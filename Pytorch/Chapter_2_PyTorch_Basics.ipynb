{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Plan**\n",
        "\n",
        "**1. Data types and constants**\n",
        "\n",
        "**2. Variables and tensors**\n",
        "\n",
        "**3. Sessions and execution**\n"
      ],
      "metadata": {
        "id": "RxIdA3ramh0X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data types and constants**"
      ],
      "metadata": {
        "id": "9Alts6dPmxSH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, understanding data types and constants is essential for efficient and effective use of the library. Here's a detailed overview of these concepts:\n",
        "\n",
        "**<h2>Data Types in PyTorch</h2>**\n",
        "\n",
        "PyTorch tensors can store data in a variety of types. These types are similar to the data types found in NumPy and are essential for optimizing performance and ensuring compatibility across different devices (CPU, GPU).\n",
        "\n",
        "**<h3>Numeric Types</h3>**\n",
        "\n",
        "1. **Integers**\n",
        "   - `torch.int8`: 8-bit signed integer\n",
        "   - `torch.uint8`: 8-bit unsigned integer\n",
        "   - `torch.int16` or `torch.short`: 16-bit signed integer\n",
        "   - `torch.int32` or `torch.int`: 32-bit signed integer\n",
        "   - `torch.int64` or `torch.long`: 64-bit signed integer\n",
        "\n",
        "2. **Floating-Point Numbers**\n",
        "   - `torch.float16` or `torch.half`: 16-bit floating-point (useful for reducing memory usage, often used in GPU computations)\n",
        "   - `torch.float32` or `torch.float`: 32-bit floating-point (default type for floating-point operations)\n",
        "   - `torch.float64` or `torch.double`: 64-bit floating-point (used when higher precision is needed)\n",
        "\n",
        "3. **Complex Numbers**\n",
        "   - `torch.complex64`: 64-bit complex number (each complex number is composed of two 32-bit floats)\n",
        "   - `torch.complex128`: 128-bit complex number (each complex number is composed of two 64-bit floats)\n",
        "\n",
        "**<h3>Boolean Type</h3>**\n",
        "\n",
        "- `torch.bool`: Boolean type, can hold `True` or `False` values.\n",
        "\n",
        "**<h2>Constants in PyTorch</h2>**\n",
        "\n",
        "PyTorch provides several constants that can be used to define various properties and behaviors in your code.\n",
        "\n",
        "1. **Mathematical Constants**\n",
        "   - `torch.pi`: The value of Ï€ (pi).\n",
        "   - `torch.e`: The base of the natural logarithm.\n",
        "\n",
        "2. **Special Constants**\n",
        "   - `torch.inf`: Represents positive infinity.\n",
        "   - `torch.nan`: Represents Not-a-Number (NaN).\n",
        "\n",
        "   ---\n",
        "\n"
      ],
      "metadata": {
        "id": "TzjDwLEYneB1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Creating Tensors with Specific Data Types**"
      ],
      "metadata": {
        "id": "QPW-DWAgoKti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Integer tensor\n",
        "int_tensor = torch.tensor([1, 2, 3], dtype=torch.int32)\n",
        "print(int_tensor.dtype)  # Output: torch.int32\n",
        "\n",
        "# Floating-point tensor\n",
        "float_tensor = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)\n",
        "print(float_tensor.dtype)  # Output: torch.float32\n",
        "\n",
        "# Complex tensor\n",
        "complex_tensor = torch.tensor([1 + 1j, 2 + 2j], dtype=torch.complex64)\n",
        "print(complex_tensor.dtype)  # Output: torch.complex64"
      ],
      "metadata": {
        "id": "VZ_DfzhooO3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Using Constants**"
      ],
      "metadata": {
        "id": "bb4QSvFloQ7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Use of mathematical constant pi\n",
        "circle_area = torch.pi * (torch.tensor(5.0) ** 2)\n",
        "print(circle_area)  # Output: tensor(78.5398)\n",
        "\n",
        "# Use of special constants\n",
        "infinity_tensor = torch.tensor([1, 2, torch.inf])\n",
        "print(infinity_tensor)  # Output: tensor([ 1.,  2., inf.])\n",
        "\n",
        "nan_tensor = torch.tensor([1, 2, torch.nan])\n",
        "print(nan_tensor)  # Output: tensor([ 1.,  2., nan.])\n"
      ],
      "metadata": {
        "id": "zUdXLmo_oabk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Device Management**\n",
        "\n",
        "In addition to data types, managing the device on which tensors are stored (CPU or GPU) is a critical aspect of PyTorch. Tensors can be moved between devices using **.to()** or **.cuda()** methods."
      ],
      "metadata": {
        "id": "CxqSIcN8ocOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor on CPU\n",
        "cpu_tensor = torch.tensor([1, 2, 3], device='cpu')\n",
        "\n",
        "# Move tensor to GPU\n",
        "gpu_tensor = cpu_tensor.to('cuda')\n",
        "print(gpu_tensor.device)  # Output: cuda:0\n",
        "\n",
        "# Alternatively, you can create a tensor directly on the GPU\n",
        "gpu_tensor_direct = torch.tensor([1, 2, 3], device='cuda')\n",
        "print(gpu_tensor_direct.device)  # Output: cuda:0"
      ],
      "metadata": {
        "id": "oZzhfuXNon7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Variables and tensors**"
      ],
      "metadata": {
        "id": "uIt6YtXgozJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>Tensors in PyTorch</h2>**\n",
        "\n",
        "A tensor is a multi-dimensional array that is a fundamental building block in PyTorch. Tensors are similar to NumPy arrays but come with additional features, such as the ability to run on GPUs and support for automatic differentiation.\n",
        "\n",
        "**Creating Tensors**\n",
        "\n",
        "You can create tensors in several ways:"
      ],
      "metadata": {
        "id": "vTmNLFTNpaBy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. From Data**"
      ],
      "metadata": {
        "id": "tWYC1Tilpldj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Creating a tensor from a Python list\n",
        "data = [1, 2, 3, 4]\n",
        "tensor_from_list = torch.tensor(data)\n",
        "print(tensor_from_list)  # Output: tensor([1, 2, 3, 4])"
      ],
      "metadata": {
        "id": "L9SDaLlSpkvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. From NumPy Arrays**"
      ],
      "metadata": {
        "id": "5dLeXQCGpqYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Creating a tensor from a NumPy array\n",
        "np_array = np.array([1, 2, 3, 4])\n",
        "tensor_from_np = torch.tensor(np_array)\n",
        "print(tensor_from_np)  # Output: tensor([1, 2, 3, 4])\n"
      ],
      "metadata": {
        "id": "HyyWstDapuFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. With Specific Initializations**"
      ],
      "metadata": {
        "id": "6W73LTDQpvum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor filled with zeros\n",
        "zeros_tensor = torch.zeros((3, 3))\n",
        "print(zeros_tensor)  # Output: tensor of shape (3, 3) filled with zeros\n",
        "\n",
        "# Tensor filled with ones\n",
        "ones_tensor = torch.ones((3, 3))\n",
        "print(ones_tensor)  # Output: tensor of shape (3, 3) filled with ones\n",
        "\n",
        "# Tensor with random values\n",
        "random_tensor = torch.rand((3, 3))\n",
        "print(random_tensor)  # Output: tensor of shape (3, 3) filled with random values between 0 and 1"
      ],
      "metadata": {
        "id": "9osjY860py0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Using torch.* Methods**"
      ],
      "metadata": {
        "id": "YA0ywNYCp03K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor with specific data type\n",
        "float_tensor = torch.FloatTensor([1.0, 2.0, 3.0])\n",
        "print(float_tensor)  # Output: tensor([1., 2., 3.])\n",
        "\n",
        "# Tensor with a specific range\n",
        "range_tensor = torch.arange(0, 10, step=2)\n",
        "print(range_tensor)  # Output: tensor([0, 2, 4, 6, 8])"
      ],
      "metadata": {
        "id": "PBpK9KH2p573"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>Tensor Operations</h2>**\n",
        "\n",
        "Tensors support a wide range of operations, including arithmetic operations, slicing, indexing, and more."
      ],
      "metadata": {
        "id": "7ofhehgnqFCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic arithmetic operations\n",
        "a = torch.tensor([1, 2, 3])\n",
        "b = torch.tensor([4, 5, 6])\n",
        "\n",
        "sum_tensor = a + b\n",
        "print(sum_tensor)  # Output: tensor([5, 7, 9])\n",
        "\n",
        "# Matrix multiplication\n",
        "mat1 = torch.tensor([[1, 2], [3, 4]])\n",
        "mat2 = torch.tensor([[5, 6], [7, 8]])\n",
        "\n",
        "product_tensor = torch.matmul(mat1, mat2)\n",
        "print(product_tensor)  # Output: tensor([[19, 22], [43, 50]])\n",
        "\n",
        "# Indexing and slicing\n",
        "tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "sliced_tensor = tensor[1:, 1:]\n",
        "print(sliced_tensor)  # Output: tensor([[5, 6], [8, 9]])"
      ],
      "metadata": {
        "id": "b0HZxE6vqIwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>Variables in PyTorch (Deprecated)</h2>**\n",
        "\n",
        "Previously, PyTorch had a Variable class for wrapping tensors to enable automatic differentiation. However, this is no longer necessary as of PyTorch 0.4.0, because tensors themselves now support autograd by default.\n",
        "Automatic Differentiation with Tensors\n",
        "\n",
        "To enable autograd (automatic differentiation) for a tensor, you need to set its requires_grad attribute to True."
      ],
      "metadata": {
        "id": "08y2jg1BqOdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor with requires_grad=True\n",
        "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
        "\n",
        "# Perform some operations\n",
        "y = x + 2\n",
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "# Backpropagate to compute gradients\n",
        "out.backward()\n",
        "print(x.grad)"
      ],
      "metadata": {
        "id": "J0I4tKceqVNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, out.backward() computes the gradient of out with respect to x. The gradient is stored in x.grad."
      ],
      "metadata": {
        "id": "a1kWqNEJqf0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary**\n",
        "\n",
        "- Tensors are the core data structure in PyTorch, used for storing and manipulating multi-dimensional arrays.\n",
        "- Tensors support various data types and can be created from lists, NumPy arrays, or initialized with specific values.\n",
        "- Tensors support a wide range of operations, including arithmetic, indexing, and slicing.\n",
        "- Variables are deprecated; now, tensors with requires_grad=True are used for automatic differentiation in PyTorch."
      ],
      "metadata": {
        "id": "w11bAg7Dqg1G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sessions and execution**"
      ],
      "metadata": {
        "id": "y2PWzybUqqsn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, sessions and execution are concepts primarily tied to how computations are managed and executed, especially in the context of neural network training and inference. Unlike TensorFlow, which uses sessions to execute graphs, PyTorch follows a more dynamic and interactive approach to computation.\n",
        "\n",
        "**Dynamic Computation Graphs**\n",
        "\n",
        "One of the key features of PyTorch is its use of dynamic computation graphs (also known as define-by-run graphs). This means the graph is built on-the-fly as operations are performed, allowing for more intuitive and flexible coding, especially for complex models.\n",
        "Key Points:\n",
        "\n",
        "- Dynamic Nature: The computation graph is built dynamically at runtime.\n",
        "- Flexibility: Easier to use for tasks that involve conditionals, loops, and other dynamic structures.\n",
        "- Interactivity: Ideal for research and development due to the ease of debugging and modifying models on-the-fly."
      ],
      "metadata": {
        "id": "MLrKih9-r1RL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>Execution in PyTorch</h2>**\n",
        "\n",
        "PyTorch does not have a separate concept of sessions like TensorFlow. Instead, it executes operations immediately as they are called."
      ],
      "metadata": {
        "id": "9a_2GkMXsBWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define a tensor\n",
        "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
        "\n",
        "# Perform some operations\n",
        "y = x + 2\n",
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "# Backpropagation to compute gradients\n",
        "out.backward()\n",
        "\n",
        "# Check the gradients\n",
        "print(x.grad)"
      ],
      "metadata": {
        "id": "9DEKUWpSsDOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>Training a Neural Network in PyTorch</h2>**\n",
        "\n",
        "The typical workflow for training a neural network in PyTorch involves the following steps:\n",
        "\n",
        "**1. Define the Model:** Create a subclass of torch.nn.Module to define the architecture of the neural network.\n",
        "\n",
        "**2. Define the Loss Function:** Choose an appropriate loss function from torch.nn or define your own.\n",
        "\n",
        "**3. Define the Optimizer:** Select an optimizer from torch.optim to update the model's parameters.\n",
        "\n",
        "**4. Training Loop:** Write a loop that iterates over the dataset, performs forward and backward passes, and updates the model parameters."
      ],
      "metadata": {
        "id": "YiqP7-_AsOMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define a simple model\n",
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleModel, self).__init__()\n",
        "        self.linear = nn.Linear(1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)\n",
        "\n",
        "# Instantiate the model, loss function, and optimizer\n",
        "model = SimpleModel()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Dummy dataset\n",
        "data = torch.tensor([[1.0], [2.0], [3.0], [4.0]])\n",
        "target = torch.tensor([[2.0], [4.0], [6.0], [8.0]])\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass\n",
        "    outputs = model(data)\n",
        "    loss = criterion(outputs, target)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()  # Clear the gradients\n",
        "    loss.backward()        # Compute the gradients\n",
        "    optimizer.step()       # Update the parameters\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "id": "iy3fglnLskdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Execution on Different Devices**\n",
        "\n",
        "PyTorch supports execution on both CPUs and GPUs. You can easily move tensors and models between devices using the .to() method."
      ],
      "metadata": {
        "id": "daWPDR9StEcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Move tensor to the specified device\n",
        "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True).to(device)\n",
        "\n",
        "# Define a simple model and move it to the device\n",
        "model = SimpleModel().to(device)\n",
        "\n",
        "# Perform operations on the device\n",
        "y = model(x)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "0U-FukqRtH0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inference**\n",
        "\n",
        "In PyTorch, when performing inference (i.e., making predictions with a trained model), you can use the torch.no_grad() context manager. This context manager temporarily sets all the requires_grad flags to false, reducing memory usage and speeding up computations because no gradients are computed.\n",
        "Why Use torch.no_grad() for Inference?\n",
        "\n",
        "**1. Memory Efficiency:** During inference, gradients are not needed. Disabling gradient computation reduces memory consumption.\n",
        "\n",
        "**2. Speed:** Without the need to track gradients, computations are faster."
      ],
      "metadata": {
        "id": "_zlw67tkuZEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference\n",
        "test_data = torch.tensor([[5.0], [6.0], [7.0], [8.0]])\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "with torch.no_grad():  # Disable gradient calculation\n",
        "    predictions = model(test_data)\n",
        "    print(\"Predictions:\", predictions)"
      ],
      "metadata": {
        "id": "EsWEvLeYuadj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary**\n",
        "\n",
        "- **Dynamic Computation Graphs:** PyTorch builds the computation graph dynamically at runtime.\n",
        "- **Execution Model:** Operations are executed immediately, without the need for sessions.\n",
        "- **Training Workflow:** Typically involves defining the model, loss function, optimizer, and a training loop.\n",
        "- **Device Management:** PyTorch allows easy execution on CPUs and GPUs, with simple methods to move data and models between devices."
      ],
      "metadata": {
        "id": "t_hf_yg6tN95"
      }
    }
  ]
}