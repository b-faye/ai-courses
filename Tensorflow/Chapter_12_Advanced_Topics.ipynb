{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Plan**\n",
        "\n",
        "**1. Introduction to AutoML with TensorFlow**\n",
        "\n",
        "**2. TensorFlow Probability**\n",
        "\n",
        "**3. Hyperparameter tuning with TensorFlow**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4EUWQZecQsJu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2> Introduction to AutoML with TensorFlow</h2>**\n",
        "\n",
        "**Definition:** AutoML (Automated Machine Learning) is a process that automates the end-to-end process of applying machine learning to real-world problems. TensorFlow offers AutoML capabilities through TensorFlow's tf.keras API and the TFX (TensorFlow Extended) ecosystem, enabling users to automatically select and tune models and preprocess data."
      ],
      "metadata": {
        "id": "4DP8q1tcK_wi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example :**\n",
        "\n",
        "TensorFlow provides a higher-level AutoML API called Keras Tuner, which simplifies hyperparameter tuning. Here’s a basic example using Keras Tuner to perform AutoML:"
      ],
      "metadata": {
        "id": "w-Hp4xEALXgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Keras Tuner\n",
        "! pip install keras-tuner"
      ],
      "metadata": {
        "id": "0LgsVWVlLiKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import keras_tuner as kt\n",
        "import numpy as np\n",
        "\n",
        "# Define the model building function\n",
        "def build_model(hp):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(units=hp.Int('units', min_value=32, max_value=512, step=32), activation='relu', input_shape=(784,)))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Initialize the tuner\n",
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=10,\n",
        "    hyperband_iterations=2,\n",
        "    directory='my_dir',\n",
        "    project_name='intro_to_kt'\n",
        ")\n",
        "\n",
        "# Dummy dataset\n",
        "x_train = np.random.random((1000, 784))\n",
        "y_train = np.random.randint(10, size=(1000,))\n",
        "x_val = np.random.random((200, 784))\n",
        "y_val = np.random.randint(10, size=(200,))\n",
        "\n",
        "# Search for the best hyperparameters\n",
        "tuner.search(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
        "\n",
        "# Get the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "print(\"Best hyperparameters found:\")\n",
        "print(tuner.get_best_hyperparameters()[0].values)"
      ],
      "metadata": {
        "id": "ntUYbJr-LgVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>TensorFlow Probability</h2>**\n",
        "\n",
        "**Definition:** TensorFlow Probability (TFP) is a library for probabilistic reasoning and statistical analysis in TensorFlow. It extends TensorFlow with functions and distributions for statistical modeling, probabilistic reasoning, and Bayesian inference.\n",
        "\n"
      ],
      "metadata": {
        "id": "kH1U_-2LMHP2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example :**\n",
        "\n",
        "Here’s an example of using TensorFlow Probability to work with probabilistic distributions:"
      ],
      "metadata": {
        "id": "szRTQ_a7MP_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install TensorFlow Probability\n",
        "!pip install tensorflow-probability\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "# Create a normal distribution\n",
        "tfd = tfp.distributions\n",
        "normal_dist = tfd.Normal(loc=0., scale=1.)\n",
        "\n",
        "# Sample from the distribution\n",
        "samples = normal_dist.sample(5)\n",
        "print(\"Samples from normal distribution:\", samples.numpy())\n",
        "\n",
        "# Compute probabilities\n",
        "probabilities = normal_dist.prob(samples)\n",
        "print(\"Probabilities of samples:\", probabilities.numpy())\n",
        "\n",
        "# Compute mean and variance\n",
        "mean = normal_dist.mean()\n",
        "variance = normal_dist.variance()\n",
        "print(\"Mean of normal distribution:\", mean.numpy())\n",
        "print(\"Variance of normal distribution:\", variance.numpy())"
      ],
      "metadata": {
        "id": "3VzhB9oXMWBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **<h2>Hyperparameter Tuning with TensorFlow</h2>**\n",
        "\n",
        "Definition: Hyperparameter tuning involves optimizing the parameters that control the learning process of a machine learning model (e.g., learning rate, number of layers). TensorFlow provides tools like Keras Tuner and integration with cloud services for hyperparameter optimization.\n",
        "\n",
        "**Example :**\n",
        "\n",
        "The example above using Keras Tuner for AutoML also covers hyperparameter tuning. Here’s a more detailed example with tf.keras and Keras Tuner:"
      ],
      "metadata": {
        "id": "UVmS188NMe0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import keras_tuner as kt\n",
        "import numpy as np\n",
        "\n",
        "# Define the model-building function\n",
        "def build_model(hp):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(units=hp.Int('units', min_value=32, max_value=512, step=32), activation='relu', input_shape=(784,)))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Initialize Keras Tuner\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=1,\n",
        "    directory='kt_dir',\n",
        "    project_name='hyperparameter_tuning'\n",
        ")\n",
        "\n",
        "# Dummy dataset\n",
        "x_train = np.random.random((1000, 784))\n",
        "y_train = np.random.randint(10, size=(1000,))\n",
        "x_val = np.random.random((200, 784))\n",
        "y_val = np.random.randint(10, size=(200,))\n",
        "\n",
        "# Search for the best hyperparameters\n",
        "tuner.search(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
        "\n",
        "# Get the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "print(\"Best hyperparameters found:\")\n",
        "print(tuner.get_best_hyperparameters()[0].values)\n"
      ],
      "metadata": {
        "id": "-UZgyt70MlU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In summary:\n",
        "\n",
        "- AutoML with TensorFlow simplifies model creation and tuning.\n",
        "- TensorFlow Probability provides tools for probabilistic modeling and statistical analysis.\n",
        "- Hyperparameter tuning optimizes the settings that influence model training and performance."
      ],
      "metadata": {
        "id": "bcQfcCG7MtEH"
      }
    }
  ]
}