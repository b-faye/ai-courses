{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Plan**\n",
        "\n",
        "**1. Running TensorFlow on cloud platforms (e.g., Google Cloud, AWS, Azure)**\n",
        "\n",
        "**2. Distributed training with TensorFlow**\n",
        "\n",
        "**3. Serving models using cloud services**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4EUWQZecQsJu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>Running TensorFlow on Cloud Platforms</h2>**\n",
        "\n",
        "**Definition:** Running TensorFlow on cloud platforms involves using cloud-based infrastructure to train and deploy TensorFlow models. Cloud platforms like Google Cloud, AWS, and Azure offer scalable resources such as virtual machines (VMs), GPUs, and TPUs that can be utilized for machine learning tasks.\n",
        "\n"
      ],
      "metadata": {
        "id": "pxnhSKknH6m6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example in Google Colab:**\n",
        "\n",
        "Google Colab itself is a cloud-based service, so you can directly use TensorFlow on it. However, if you want to interact with Google Cloud services from Colab, here’s an example of how you might set up your environment and use Google Cloud resources:"
      ],
      "metadata": {
        "id": "VwdRrUCRIMAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, make sure to install necessary packages\n",
        "!pip install google-cloud-storage\n",
        "\n",
        "from google.cloud import storage\n",
        "\n",
        "# Set up authentication (you will need to authenticate in Colab)\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Initialize Google Cloud Storage client\n",
        "client = storage.Client()\n",
        "\n",
        "# List buckets\n",
        "buckets = list(client.list_buckets())\n",
        "print(\"Buckets:\")\n",
        "for bucket in buckets:\n",
        "    print(bucket.name)\n"
      ],
      "metadata": {
        "id": "7ReFwNpQIQ1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run this code, you'll need to authenticate and have access to a Google Cloud project. This code lists available Cloud Storage buckets."
      ],
      "metadata": {
        "id": "RG-lR37hIUX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>Distributed Training with TensorFlow</h2>**\n",
        "\n",
        "**Definition:** Distributed training involves splitting a model's training workload across multiple devices or machines to speed up the process. TensorFlow supports distributed training using strategies such as tf.distribute.MirroredStrategy for synchronous training across multiple GPUs and tf.distribute.MultiWorkerMirroredStrategy for distributed training across multiple machines."
      ],
      "metadata": {
        "id": "d2868lWJIXfq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example in Google Colab:**\n",
        "\n",
        "Google Colab provides a limited number of GPUs, but you can use the following code to set up distributed training with tf.distribute.MirroredStrategy:"
      ],
      "metadata": {
        "id": "DPsppDaiIl7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Set up MirroredStrategy for distributed training\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
        "\n",
        "# Build and compile the model within the strategy scope\n",
        "with strategy.scope():\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(64, activation='relu', input_shape=(784,)),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Dummy dataset\n",
        "import numpy as np\n",
        "x_train = np.random.random((1000, 784))\n",
        "y_train = np.random.randint(10, size=(1000,))\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5)"
      ],
      "metadata": {
        "id": "WX9YiZXiIi87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>Serving Models Using Cloud Services**\n",
        "\n",
        "Definition: Serving models involves deploying a trained model so that it can be used for inference in a production environment. Cloud services offer managed solutions for serving models, which include endpoints for making predictions."
      ],
      "metadata": {
        "id": "POwTSVZvIug-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example in Google Cloud Platform (GCP):**\n",
        "\n",
        "To serve a model using Google Cloud AI Platform, you would typically follow these steps:\n",
        "\n",
        "- Upload the Model to Google Cloud Storage\n",
        "- Deploy the Model using AI Platform\n",
        "\n",
        "Here's a simplified code example showing how to deploy a model in Google Cloud AI Platform:"
      ],
      "metadata": {
        "id": "BYeYZYctI5Bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "# Set up Google Cloud AI Platform\n",
        "aiplatform.init(project='your-project-id', location='us-central1')\n",
        "\n",
        "# Upload the model to Google Cloud Storage\n",
        "model_dir = 'gs://your-bucket/model/'\n",
        "\n",
        "# Create a model\n",
        "model = aiplatform.Model.upload(display_name='my_model', artifact_uri=model_dir)\n",
        "\n",
        "# Deploy the model\n",
        "endpoint = model.deploy(\n",
        "    machine_type='n1-standard-4',\n",
        "    endpoint_name='my-endpoint'\n",
        ")\n",
        "\n",
        "print(f'Model deployed to endpoint: {endpoint.name}')\n"
      ],
      "metadata": {
        "id": "fI_c6BDKI2XE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You’ll need to replace `'your-project-id'`, `'gs://your-bucket/model/'`, and other placeholders with your actual values. This code demonstrates how to initialize the AI Platform, upload a model, and deploy it to an endpoint for serving predictions.\n",
        "\n",
        "Feel free to adapt these examples according to your specific needs and cloud provider!"
      ],
      "metadata": {
        "id": "HJn2lrmeJEqZ"
      }
    }
  ]
}