{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Plan**\n",
        "\n",
        "**1. Custom Layers**\n",
        "\n",
        "**2. Custom Models**\n",
        "\n",
        "**3. Callbacks and Custom Training Loops**\n",
        "\n",
        "**4. Model Saving and Loading**"
      ],
      "metadata": {
        "id": "4EUWQZecQsJu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>1. Custom Layers</h2>**\n",
        "\n",
        "A custom layer is a subclass of tf.keras.layers.Layer that allows you to define its own forward pass and manage its own weights.\n",
        "\n",
        "**Key Methods:**\n",
        "\n",
        "- init: Initialize the layer.\n",
        "- build: Create the weights of the layer.\n",
        "- call: Define the forward pass.\n",
        "- get_config: Serialize the layer configuration."
      ],
      "metadata": {
        "id": "o8wEqAxBczKz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 1: Simple Custom Layer**\n",
        "\n",
        "**Objective:** Create a layer that adds a constant value to the input"
      ],
      "metadata": {
        "id": "pWTR3tDldVKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class AddConstantLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, constant_value=1, **kwargs):\n",
        "        super(AddConstantLayer, self).__init__(**kwargs)\n",
        "        self.constant_value = constant_value\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return inputs + self.constant_value\n",
        "\n",
        "# Usage\n",
        "inputs = tf.keras.Input(shape=(4,))\n",
        "outputs = AddConstantLayer(constant_value=5)(inputs)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86gl52FqdJWM",
        "outputId": "c18614ac-2ccb-4a15-bf12-4737417ada83"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 4)]               0         \n",
            "                                                                 \n",
            " add_constant_layer (AddCon  (None, 4)                 0         \n",
            " stantLayer)                                                     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 0 (0.00 Byte)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 2: Custom Layer with Trainable Weights**\n",
        "\n",
        "**Objective:** Create a layer that learns a bias term"
      ],
      "metadata": {
        "id": "rqQ0zBxxdyHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BiasLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(BiasLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.bias = self.add_weight(shape=(input_shape[-1],), initializer='zeros', trainable=True)\n",
        "        super(BiasLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return inputs + self.bias\n",
        "\n",
        "# Usage\n",
        "inputs = tf.keras.Input(shape=(4,))\n",
        "outputs = BiasLayer()(inputs)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkxyXQwXoCIP",
        "outputId": "eb385dfe-33f6-4951-ce66-58d3ca31e10c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 4)]               0         \n",
            "                                                                 \n",
            " bias_layer (BiasLayer)      (None, 4)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4 (16.00 Byte)\n",
            "Trainable params: 4 (16.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 3: Custom Dense Layer with Activation**\n",
        "\n",
        "**Objective:** Create a dense layer with activation"
      ],
      "metadata": {
        "id": "JENcJEHXoYpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class CustomDenseLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units=32, activation=None, **kwargs):\n",
        "        super(CustomDenseLayer, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight(\n",
        "            shape=(input_shape[-1], self.units),\n",
        "            initializer='glorot_uniform',\n",
        "            trainable=True\n",
        "        )\n",
        "        self.bias = self.add_weight(\n",
        "            shape=(self.units,),\n",
        "            initializer='zeros',\n",
        "            trainable=True\n",
        "        )\n",
        "        super(CustomDenseLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        output = tf.matmul(inputs, self.kernel) + self.bias\n",
        "        if self.activation:\n",
        "            output = self.activation(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "# Usage\n",
        "inputs = tf.keras.Input(shape=(4,))\n",
        "outputs = CustomDenseLayer(units=8, activation='relu')(inputs)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7-NejuaodeG",
        "outputId": "b5d484aa-8750-4bd7-c5c3-9e5001b934c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 4)]               0         \n",
            "                                                                 \n",
            " custom_dense_layer (Custom  (None, 8)                 40        \n",
            " DenseLayer)                                                     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40 (160.00 Byte)\n",
            "Trainable params: 40 (160.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 4: Custom Layer with Configuration**\n",
        "\n",
        "**Objective:** Create a layer that can be serialized and deserialized"
      ],
      "metadata": {
        "id": "lhIbzwn7pLBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SerializableLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, constant_value=1, **kwargs):\n",
        "        super(SerializableLayer, self).__init__(**kwargs)\n",
        "        self.constant_value = constant_value\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return inputs + self.constant_value\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(SerializableLayer, self).get_config()\n",
        "        config.update({'constant_value': self.constant_value})\n",
        "        return config\n",
        "\n",
        "# Usage\n",
        "inputs = tf.keras.Input(shape=(4,))\n",
        "outputs = SerializableLayer(constant_value=5)(inputs)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Serialize and deserialize\n",
        "config = model.layers[1].get_config()\n",
        "new_layer = SerializableLayer.from_config(config)"
      ],
      "metadata": {
        "id": "CXA7Ukf7pR3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>2. Custom Models</h2>**\n",
        "\n",
        "A custom model is a subclass of tf.keras.Model that allows you to define custom training, evaluation, and prediction logic.\n",
        "\n",
        "**Key Methods:**\n",
        "\n",
        "- __init__: Initialize the model.\n",
        "- call: Define the forward pass.\n",
        "- train_step: Custom training logic.\n",
        "- test_step: Custom evaluation logic.\n",
        "- compile: Compile the model with loss, optimizer, and metrics.\n",
        "- metrics: Define custom metrics."
      ],
      "metadata": {
        "id": "GZr2TsO5pUCM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 1: Simple Custom Model**\n",
        "\n",
        "**Objective:** Create a model using functional API"
      ],
      "metadata": {
        "id": "j9oiDxYoqVxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCustomModel(tf.keras.Model):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(SimpleCustomModel, self).__init__(**kwargs)\n",
        "        self.dense = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.dense(inputs)\n",
        "\n",
        "# Usage\n",
        "model = SimpleCustomModel()\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Generate some dummy data\n",
        "import numpy as np\n",
        "x_train = np.random.random((100, 4))\n",
        "y_train = np.random.random((100, 1))\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5)"
      ],
      "metadata": {
        "id": "h7L79BJQqUBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 2: Custom Model with Custom Layer**\n",
        "\n",
        "**Objective:** Use a custom layer in the model"
      ],
      "metadata": {
        "id": "LXNnE07Bqjho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelWithCustomLayer(tf.keras.Model):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(ModelWithCustomLayer, self).__init__(**kwargs)\n",
        "        self.dense1 = tf.keras.layers.Dense(4, activation='relu')\n",
        "        self.custom_layer = CustomDenseLayer(units=8, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        x = self.custom_layer(x)\n",
        "        return self.dense2(x)\n",
        "\n",
        "# Usage\n",
        "model = ModelWithCustomLayer()\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Generate some dummy data\n",
        "import numpy as np\n",
        "x_train = np.random.random((100, 4))\n",
        "y_train = np.random.random((100, 1))\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5)"
      ],
      "metadata": {
        "id": "_4XSd2rtqxTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 3: Custom Training Step**\n",
        "\n",
        "**Objective:** Override **train_step** to customize training logic"
      ],
      "metadata": {
        "id": "ie2fZC8kslqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTrainingModel(tf.keras.Model):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(CustomTrainingModel, self).__init__(**kwargs)\n",
        "        self.dense1 = tf.keras.layers.Dense(4, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        return self.dense2(x)\n",
        "\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)\n",
        "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
        "\n",
        "        # calculate the gradients\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        # update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        # update metrics\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "# Usage\n",
        "import numpy as np\n",
        "x_train = np.random.random((100, 4))\n",
        "y_train = np.random.random((100, 1))\n",
        "model = CustomTrainingModel()\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "model.fit(x_train, y_train, epochs=5)"
      ],
      "metadata": {
        "id": "f-nj_Kqksr3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 4: Custom Test Step and Metrics**\n",
        "\n",
        "**Objective:** Override **test_step** and define custom metrics"
      ],
      "metadata": {
        "id": "KaH_0WMztpRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AdvancedCustomModel(tf.keras.Model):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AdvancedCustomModel, self).__init__(**kwargs)\n",
        "        self.dense1 = tf.keras.layers.Dense(4, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(1)\n",
        "        self.mae_metric = tf.keras.metrics.MeanAbsoluteError(name='mae')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        return self.dense2(x)\n",
        "\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)\n",
        "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        x, y = data\n",
        "        y_pred = self(x, training=False)\n",
        "        loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "# Usage\n",
        "import numpy as np\n",
        "x_train = np.random.random((100, 4))\n",
        "y_train = np.random.random((100, 1))\n",
        "x_test = np.random.random((20, 4))\n",
        "y_test = np.random.random((20, 1))\n",
        "model = AdvancedCustomModel()\n",
        "model.compile(optimizer='adam', loss='mse', metrics=[model.mae_metric])\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "LtkS58jPtwND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 3: Advanced Custom Model with Validation Metrics**\n",
        "\n",
        "**Objective:** Add validation metrics handling in the custom model."
      ],
      "metadata": {
        "id": "s80mLbJQwoEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AdvancedCustomModel(tf.keras.Model):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AdvancedCustomModel, self).__init__(**kwargs)\n",
        "        self.dense1 = tf.keras.layers.Dense(4, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(1)\n",
        "        self._mae_metric = tf.keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
        "        self._mse_metric = tf.keras.metrics.MeanSquaredError(name=\"mse\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        return self.dense2(x)\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self._mae_metric, self._mse_metric]\n",
        "\n",
        "    def compile(self, optimizer, loss, **kwargs):\n",
        "        super(AdvancedCustomModel, self).compile(**kwargs)\n",
        "        self.optimizer = optimizer\n",
        "        self.compiled_loss = loss\n",
        "\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)\n",
        "            loss = self.compiled_loss(y, y_pred)\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        self._mae_metric.update_state(y, y_pred)\n",
        "        self._mse_metric.update_state(y, y_pred)\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        x, y = data\n",
        "        y_pred = self(x, training=False)\n",
        "        loss = self.compiled_loss(y, y_pred)\n",
        "        self._mae_metric.update_state(y, y_pred)\n",
        "        self._mse_metric.update_state(y, y_pred)\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "# Usage\n",
        "model = AdvancedCustomModel()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.MeanSquaredError())\n",
        "\n",
        "# Generate some dummy data\n",
        "x_train = np.random.random((100, 4))\n",
        "y_train = np.random.random((100, 1))\n",
        "x_val = np.random.random((20, 4))\n",
        "y_val = np.random.random((20, 1))\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, validation_data=(x_val, y_val))\n",
        "\n",
        "# Evaluate the model\n",
        "model.evaluate(x_val, y_val)"
      ],
      "metadata": {
        "id": "Xg2PMUhAxNxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example: Training with train_on_batch**\n",
        "\n",
        "**Objective:** Train the model using train_on_batch for more granular control over the training process."
      ],
      "metadata": {
        "id": "bUOEnQY2xl5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "class AdvancedCustomModel(tf.keras.Model):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AdvancedCustomModel, self).__init__(**kwargs)\n",
        "        self.dense1 = tf.keras.layers.Dense(4, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(1)\n",
        "        self._mae_metric = tf.keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
        "        self._mse_metric = tf.keras.metrics.MeanSquaredError(name=\"mse\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        return self.dense2(x)\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self._mae_metric, self._mse_metric]\n",
        "\n",
        "    def compile(self, optimizer, loss, **kwargs):\n",
        "        super(AdvancedCustomModel, self).compile(**kwargs)\n",
        "        self.optimizer = optimizer\n",
        "        self.compiled_loss = loss\n",
        "\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)\n",
        "            loss = self.compiled_loss(y, y_pred)\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        self._mae_metric.update_state(y, y_pred)\n",
        "        self._mse_metric.update_state(y, y_pred)\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        x, y = data\n",
        "        y_pred = self(x, training=False)\n",
        "        loss = self.compiled_loss(y, y_pred)\n",
        "        self._mae_metric.update_state(y, y_pred)\n",
        "        self._mse_metric.update_state(y, y_pred)\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "# Usage\n",
        "model = AdvancedCustomModel()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.MeanSquaredError())\n",
        "\n",
        "# Generate some dummy data\n",
        "x_train = np.random.random((100, 4))\n",
        "y_train = np.random.random((100, 1))\n",
        "\n",
        "# Batch size\n",
        "batch_size = 16\n",
        "\n",
        "# Training using train_on_batch\n",
        "for epoch in range(5):\n",
        "    print(f'Start of epoch {epoch}')\n",
        "    for start in range(0, len(x_train), batch_size):\n",
        "        end = start + batch_size\n",
        "        x_batch = x_train[start:end]\n",
        "        y_batch = y_train[start:end]\n",
        "        model.train_on_batch(x_batch, y_batch)\n",
        "\n",
        "    # Print metrics at the end of each epoch\n",
        "    print(f'Epoch {epoch} metrics:')\n",
        "    for metric in model.metrics:\n",
        "        print(f'{metric.name}: {metric.result().numpy()}')\n",
        "    # Reset metrics at the end of each epoch\n",
        "    for metric in model.metrics:\n",
        "        metric.reset_states()"
      ],
      "metadata": {
        "id": "zgRSbc4mxrK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>3.  Callbacks and Custom Training Loops</h2>**\n",
        "\n",
        "Callbacks are objects that can perform actions at various stages of training. Custom training loops provide more control over the training process."
      ],
      "metadata": {
        "id": "g_t70smsyneh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 1: Simple Custom Callback**\n",
        "\n",
        "**Objective:** Print a message at the start and end of each epoch"
      ],
      "metadata": {
        "id": "VnGm6ytC3lQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        print(f\"Starting epoch {epoch}\")\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print(f\"End of epoch {epoch}\")\n",
        "\n",
        "# Usage\n",
        "model.fit(x_train, y_train, epochs=5, callbacks=[SimpleCallback()])"
      ],
      "metadata": {
        "id": "qXBYm0sE3koC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 2: Custom Callback for Learning Rate Adjustment**\n",
        "\n",
        "**Objective:** Adjust the learning rate dynamically"
      ],
      "metadata": {
        "id": "w586vgpl3vT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LearningRateSchedulerCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        new_lr = 0.01 * (0.1 ** (epoch // 10))\n",
        "        tf.keras.backend.set_value(self.model.optimizer.lr, new_lr)\n",
        "        print(f\"Epoch {epoch}: Learning rate is {new_lr}\")\n",
        "\n",
        "# Usage\n",
        "model.fit(x_train, y_train, epochs=20, callbacks=[LearningRateSchedulerCallback()])"
      ],
      "metadata": {
        "id": "lsjhUWDJ3zxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 3: Custom Training Loop with GradientTape**\n",
        "\n",
        "**Objective:** Full control over training loop"
      ],
      "metadata": {
        "id": "UqDKia8e32hw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Generate some dummy data\n",
        "x_train = np.random.random((100, 2))\n",
        "y_train = np.random.random((100, 1))\n",
        "\n",
        "# Define the optimizer, loss function, and metrics\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_fn = tf.keras.losses.MeanSquaredError()\n",
        "train_acc_metric = tf.keras.metrics.MeanAbsoluteError()\n",
        "\n",
        "# Define the training step function\n",
        "@tf.function\n",
        "def train_step(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = model(x, training=True)\n",
        "        loss_value = loss_fn(y, y_pred)\n",
        "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    train_acc_metric.update_state(y, y_pred)\n",
        "    return loss_value\n",
        "\n",
        "# Convert the data to tf.data.Dataset and batch it\n",
        "batch_size = 16\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
        "\n",
        "# Training loop\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Start of epoch {epoch}\")\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "        loss_value = train_step(x_batch_train, y_batch_train)\n",
        "        if step % 10 == 0:\n",
        "            print(f\"Training loss (for one batch) at step {step}: {loss_value:.4f}\")\n",
        "    train_acc = train_acc_metric.result()\n",
        "    print(f\"Training accuracy over epoch: {train_acc:.4f}\")\n",
        "      .reset_states()\n"
      ],
      "metadata": {
        "id": "hOQuICfX38J9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>4. Model Saving and Loading</h2>**\n",
        "\n",
        "Saving and loading models in TensorFlow involves serializing the model architecture and its weights to disk and restoring them later."
      ],
      "metadata": {
        "id": "vSFckpLB4Hsz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 1:** Save model that doesn't contain custom layer"
      ],
      "metadata": {
        "id": "F21q3FyqPEYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Generate some dummy data\n",
        "x_train = np.random.random((100, 2))\n",
        "y_train = np.random.random((100, 1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5)"
      ],
      "metadata": {
        "id": "JhcgLOXWO3C2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save('simple_model.h5')\n",
        "\n",
        "# Load the model\n",
        "loaded_model = tf.keras.models.load_model('simple_model.h5')\n",
        "loaded_model.summary()"
      ],
      "metadata": {
        "id": "nDI6UX9K4TmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 2:** Save model that contain custom layer"
      ],
      "metadata": {
        "id": "DZCf2HC_PZOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "@keras.saving.register_keras_serializable()\n",
        "class CustomDenseLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units=32, activation=None, **kwargs):\n",
        "        super(CustomDenseLayer, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight(\n",
        "            shape=(input_shape[-1], self.units),\n",
        "            initializer='glorot_uniform',\n",
        "            trainable=True\n",
        "        )\n",
        "        self.bias = self.add_weight(\n",
        "            shape=(self.units,),\n",
        "            initializer='zeros',\n",
        "            trainable=True\n",
        "        )\n",
        "        super(CustomDenseLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        output = tf.matmul(inputs, self.kernel) + self.bias\n",
        "        if self.activation:\n",
        "            output = self.activation(output)\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(CustomDenseLayer, self).get_config()\n",
        "        config.update({\n",
        "            'units': self.units,\n",
        "            'activation': tf.keras.activations.serialize(self.activation),\n",
        "        })\n",
        "        return config\n",
        "\n",
        "@keras.saving.register_keras_serializable()\n",
        "class ModelWithCustomLayer(tf.keras.Model):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(ModelWithCustomLayer, self).__init__(**kwargs)\n",
        "        self.dense1 = tf.keras.layers.Dense(4, activation='relu')\n",
        "        self.custom_layer = CustomDenseLayer(units=8, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        x = self.custom_layer(x)\n",
        "        return self.dense2(x)\n",
        "\n",
        "# Create and compile the model\n",
        "model = ModelWithCustomLayer()\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Generate some dummy data\n",
        "x_train = np.random.random((100, 4))\n",
        "y_train = np.random.random((100, 1))\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5)"
      ],
      "metadata": {
        "id": "DGXzLAMk-gYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save('model_with_custom_layer.keras')\n",
        "\n",
        "# Load the model\n",
        "loaded_model = tf.keras.models.load_model('model_with_custom_layer.keras', custom_objects={'CustomDenseLayer': CustomDenseLayer})"
      ],
      "metadata": {
        "id": "ILXimoQ_-giM"
      },
      "execution_count": 50,
      "outputs": []
    }
  ]
}