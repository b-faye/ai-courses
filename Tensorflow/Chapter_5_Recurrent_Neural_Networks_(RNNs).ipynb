{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>Basics of Sequential Data</h2>**\n",
        "\n",
        "Sequential data is data where the order of data points matters. Examples include time series, natural language text, and audio signals. Unlike traditional feedforward neural networks that treat inputs as independent, Recurrent Neural Networks (RNNs) are designed to handle sequential data by maintaining a hidden state that captures information from previous inputs."
      ],
      "metadata": {
        "id": "TOGhUIP94oN6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>Introduction to Recurrent Neural Networks (RNNs)</h2>**\n",
        "\n",
        "RNNs are a class of neural networks that are particularly effective for sequential data. They have connections that loop back on themselves, allowing information to persist over time. This capability makes them suitable for tasks such as language modeling, time series prediction, and sequence-to-sequence tasks."
      ],
      "metadata": {
        "id": "LTb3QRdh4sNB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>Key Components of RNNs</h2>**\n",
        "\n",
        "RNNs consist of several types of layers, each serving a specific purpose in handling sequential data. Below, we describe these layers in detail, along with code examples for building, fitting, and predicting using these layers."
      ],
      "metadata": {
        "id": "NYP_iu6c5ZTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>1. Simple RNN Layer</h2>**\n",
        "\n",
        "Purpose: To process sequential data by maintaining a hidden state that captures information from previous inputs.\n",
        "\n",
        "**Example: Simple RNN**"
      ],
      "metadata": {
        "id": "OobYZaug5lNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Generate dummy sequential data\n",
        "import numpy as np\n",
        "X_train = np.random.random((100, 10, 1))  # 100 samples, 10 timesteps, 1 feature\n",
        "y_train = np.random.randint(2, size=(100, 1))\n",
        "\n",
        "# Build a simple RNN model\n",
        "model = models.Sequential([\n",
        "    layers.SimpleRNN(32, activation='relu', input_shape=(10, 1)),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Predict\n",
        "predictions = model.predict(X_train)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCx6dUBX5t8p",
        "outputId": "bcc70caa-ebd3-4b76-8e33-08e1162d77c8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 32)                1088      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1121 (4.38 KB)\n",
            "Trainable params: 1121 (4.38 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Generate dummy sequential data\n",
        "import numpy as np\n",
        "X_train = np.random.random((100, 10, 1))  # 100 samples, 10 timesteps, 1 feature\n",
        "y_train = np.random.randint(2, size=(100, 1))\n",
        "\n",
        "# Build a simple RNN model\n",
        "model = models.Sequential([\n",
        "    layers.SimpleRNN(32, activation='relu', input_shape=(10, 1), return_sequences=True),\n",
        "    layers.SimpleRNN(32, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Predict\n",
        "predictions = model.predict(X_train)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppnxQy55585x",
        "outputId": "6015c314-1f72-4339-c91f-e7b5312dfa49"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_1 (SimpleRNN)    (None, 10, 32)            1088      \n",
            "                                                                 \n",
            " simple_rnn_2 (SimpleRNN)    (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3201 (12.50 KB)\n",
            "Trainable params: 3201 (12.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>2. Long Short-Term Memory (LSTM) Networks</h2>**\n",
        "\n",
        "Purpose: To overcome the limitations of simple RNNs in capturing long-term dependencies by using a more complex architecture with gates to control the flow of information.\n",
        "\n",
        "**Example: LSTM**"
      ],
      "metadata": {
        "id": "mUOax4L-6PQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate dummy sequential data\n",
        "X_train = np.random.random((100, 10, 1))\n",
        "y_train = np.random.randint(2, size=(100, 1))\n",
        "\n",
        "# Build an LSTM model\n",
        "model = models.Sequential([\n",
        "    layers.LSTM(32, activation='tanh', input_shape=(10, 1)),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Predict\n",
        "predictions = model.predict(X_train)\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnRbHto56ZxR",
        "outputId": "cdbbb11e-2107-47cc-8780-4ee1c6f69f3c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 32)                4352      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4385 (17.13 KB)\n",
            "Trainable params: 4385 (17.13 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>3. Gated Recurrent Unit (GRU)</h2>**\n",
        "\n",
        "Purpose: To offer a simpler alternative to LSTMs while still addressing the vanishing gradient problem, providing a good balance between simplicity and performance.\n",
        "\n",
        "**Example: GRU**"
      ],
      "metadata": {
        "id": "JRprOghs6j_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate dummy sequential data\n",
        "X_train = np.random.random((100, 10, 1))\n",
        "y_train = np.random.randint(2, size=(100, 1))\n",
        "\n",
        "# Build a GRU model\n",
        "model = models.Sequential([\n",
        "    layers.GRU(32, activation='tanh', input_shape=(10, 1)),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Predict\n",
        "predictions = model.predict(X_train)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajH1rTDn6tp7",
        "outputId": "3e2f9bf9-9a6f-4cc7-db8c-3ab38964567f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru (GRU)                   (None, 32)                3360      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3393 (13.25 KB)\n",
            "Trainable params: 3393 (13.25 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>4. TimeDistributed Layer</h2>**\n",
        "\n",
        "Purpose: To apply a layer (e.g., Dense) to every temporal slice of an input. This is useful when you need to apply the same operation across each time step independently, often used in combination with RNNs to handle sequential data where each time step is processed separately.\n",
        "\n",
        "**Example: TimeDistributed**\n",
        "\n",
        "Consider a sequence classification task where each time step in the sequence needs to be processed independently by a dense layer before passing the result to an RNN layer."
      ],
      "metadata": {
        "id": "zmrs2wgy606r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate dummy sequential data\n",
        "X_train = np.random.random((100, 10, 8))  # 100 samples, 10 timesteps, 8 features\n",
        "y_train = np.random.randint(2, size=(100, 1))\n",
        "\n",
        "# Build a model using TimeDistributed\n",
        "model = models.Sequential([\n",
        "    layers.TimeDistributed(layers.Dense(16, activation='relu'), input_shape=(10, 8)),\n",
        "    layers.LSTM(32, activation='tanh'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Predict\n",
        "predictions = model.predict(X_train)\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BABoQkyc7EmG",
        "outputId": "27802f3a-5072-484f-fc3f-ee153f021d36"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed (TimeDist  (None, 10, 16)            144       \n",
            " ributed)                                                        \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 32)                6272      \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6449 (25.19 KB)\n",
            "Trainable params: 6449 (25.19 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>Summary</h2>**\n",
        "\n",
        "- Sequential Data: Data where the order of data points is important.\n",
        "- Simple RNN: Basic recurrent network maintaining a hidden state over time.\n",
        "- LSTM: Advanced RNN designed to capture long-term dependencies using gates.\n",
        "- GRU: Simplified version of LSTM offering a good balance between performance and computational efficiency.\n",
        "- TimeDistributed: Applies a layer to each temporal slice of input, useful for processing each time step independently in a sequence."
      ],
      "metadata": {
        "id": "NUrA9BH27cMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = layers.LSTM(32, activation='tanh')(np.random.random((100, 10, 1)))\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvtI7LaL8gYu",
        "outputId": "0b30dfcf-dce5-494f-9fb3-f85f4eff90ee"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([100, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = layers.LSTM(32, activation='tanh', return_sequences=True)(np.random.random((100, 10, 1)))\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmiHRf4T8s72",
        "outputId": "9e5238eb-168f-42f9-9d1d-92da0fc49850"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([100, 10, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output, h, c = layers.LSTM(32, activation='tanh', return_state=True)(np.random.random((100, 10, 1)))\n",
        "print(f\"Output: {output.shape}\")\n",
        "print(f\"Hidden State: {h.shape}\") # output = h\n",
        "print(f\"Cell State: {c.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCH_pKJE8x_O",
        "outputId": "d0cf8f40-a295-4e1b-ffe5-8dccb14ae290"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: (100, 32)\n",
            "Hidden State: (100, 32)\n",
            "Cell State: (100, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output, h, c = layers.LSTM(32, activation='tanh', return_sequences=True, return_state=True)(np.random.random((100, 10, 1)))\n",
        "print(f\"Output: {output.shape}\")\n",
        "print(f\"Hidden State: {h.shape}\") # h corresponds to the last element of output\n",
        "print(f\"Cell State: {c.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ7_skIG9Ira",
        "outputId": "a233c2ae-09a4-43af-9c47-9060287ffe15"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: (100, 10, 32)\n",
            "Hidden State: (100, 32)\n",
            "Cell State: (100, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>5. Output Shapes and Paramters</h2>**\n",
        "\n",
        "1. **Output Shapes**:\n",
        "   - **Default**: Returns `(None, units)`.\n",
        "   - **With `return_sequences=True`**: Returns `(None, sequence, units)`.\n",
        "   - **With `return_state=True`**: Returns two outputs: `(None, units)` and `(None, units)`.\n",
        "   - **With `return_sequences=True` and `return_state=True`**: Returns two outputs: `(None, sequence, units)` and `(None, units)`.\n",
        "\n",
        "   **Note**: This is applicable for GRU. For LSTM, `return_state=True` returns two states: `(None, units)` for `hidden_state` and `(None, units)` for `cell_state`.\n",
        "\n",
        "2. **Parameters**:\n",
        "   - The input consists of two concatenated vectors: `x` (the last dimension of the input: `shape[-1]`) and `h`. `x` is the input token and `h` is the hidden state.\n",
        "   - **RNN**: `(x + h) × h + h`\n",
        "   - **LSTM**: `4 × [(x + h) × h + h]`\n",
        "   - **GRU**: `3 × [(x + h) × h + h]`\n"
      ],
      "metadata": {
        "id": "TWrBSkrt9-ZD"
      }
    }
  ]
}