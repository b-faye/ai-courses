{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Plan:**\n",
        "\n",
        "\n",
        "**1. Concurrency and parallelism in Python**\n",
        "\n",
        "**2. Python's GIL (Global Interpreter Lock)**\n",
        "\n",
        "**3. Asyncio and asynchronous programming**\n"
      ],
      "metadata": {
        "id": "x5bnCkv7eQBX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Concurrency and parallelism in Python**\n"
      ],
      "metadata": {
        "id": "CVcSbeRVebmy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concurrency and parallelism are concepts related to the execution of multiple tasks or processes in Python:\n",
        "\n",
        "1. **Concurrency:**\n",
        "   Concurrency refers to the ability of a Python program to handle multiple tasks or processes simultaneously. In concurrent programming, tasks may not run simultaneously but are interleaved or overlapped in execution. Concurrency is typically achieved through techniques such as multitasking, multithreading, or asynchronous programming. Python's `asyncio` module and `threading` module are commonly used for implementing concurrency.\n",
        "\n",
        "2. **Parallelism:**\n",
        "   Parallelism, on the other hand, refers to the ability of a Python program to execute multiple tasks or processes simultaneously by utilizing multiple CPU cores or processors. In parallel programming, tasks are truly executed concurrently, with each task running simultaneously on a separate CPU core or processor. Parallelism is often achieved through techniques such as multiprocessing or parallel computing libraries like `multiprocessing` or `joblib` in Python.\n",
        "\n",
        "In summary, concurrency focuses on managing and coordinating multiple tasks efficiently, while parallelism focuses on executing multiple tasks simultaneously to achieve improved performance, especially on multi-core systems. Python provides various libraries and modules to support both concurrency and parallelism, allowing developers to write efficient and scalable concurrent and parallel programs."
      ],
      "metadata": {
        "id": "wzOLcovWfJr6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Concurrency Example using asyncio**"
      ],
      "metadata": {
        "id": "xkVk4gT5f-Oj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNMcah5Vd_-T"
      },
      "outputs": [],
      "source": [
        "# The code will not work on colab\n",
        "import asyncio\n",
        "\n",
        "# Define a coroutine function\n",
        "async def greet(name):\n",
        "    print(f\"Hello, {name}!\")\n",
        "    # NB: if a function uses sleep, it allows other tasks to run concurrently while it's running\n",
        "    await asyncio.sleep(1)\n",
        "    print(f\"Goodbye, {name}!\")\n",
        "\n",
        "# Run coroutines concurrently\n",
        "async def main():\n",
        "    await asyncio.gather(\n",
        "        greet(\"Alice\"),\n",
        "        greet(\"Bob\"),\n",
        "        greet(\"Charlie\")\n",
        "    )\n",
        "\n",
        "# Call asyncio.run() to start the event loop\n",
        "asyncio.run(main())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move the code below on this file\n",
        "! touch concurrency.py"
      ],
      "metadata": {
        "id": "DG9oSB7agXDR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python3 concurrency.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4Ty4CSogcxW",
        "outputId": "ae27c2e5-f2d6-4b22-cb54-dc6902a75a59"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, Alice!\n",
            "Hello, Bob!\n",
            "Hello, Charlie!\n",
            "Goodbye, Alice!\n",
            "Goodbye, Bob!\n",
            "Goodbye, Charlie!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Difference between function with async and without async:**\n",
        "- **Without `async`:** In the synchronous version, `factorial()` is a regular function that calculates the factorial of a number synchronously using a loop. While the calculation is in progress, the program is blocked, and no other tasks can be executed.\n",
        "- **With `async`:** In the asynchronous version, `factorial_async()` is an asynchronous function defined with `async`. Although in this simple example it doesn't involve I/O, the function is designed to be non-blocking and allows other tasks to run concurrently while it's running. The `await asyncio.sleep(0.1)` line simulates an I/O-bound operation (e.g., network request, file I/O) to demonstrate the potential for concurrency.\n",
        "\n",
        "In summary, the asynchronous version allows for non-blocking execution, enabling other tasks to run concurrently while the factorial calculation is in progress. This can be particularly beneficial for I/O-bound operations, where the program would otherwise be waiting for external resources."
      ],
      "metadata": {
        "id": "GgJTHGBlmu_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate factorial synchronously (blocking)\n",
        "def factorial(n):\n",
        "    result = 1\n",
        "    for i in range(1, n + 1):\n",
        "        result *= i\n",
        "    return result\n",
        "\n",
        "# Example usage\n",
        "num = 5\n",
        "fact = factorial(num)\n",
        "print(f\"The factorial of {num} is {fact}\")\n"
      ],
      "metadata": {
        "id": "P-AivqoKmnwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "\n",
        "# Asynchronous function to calculate factorial asynchronously (non-blocking)\n",
        "async def factorial_async(n):\n",
        "    result = 1\n",
        "    for i in range(1, n + 1):\n",
        "        result *= i\n",
        "        # Simulate I/O-bound operation\n",
        "        await asyncio.sleep(0.1)\n",
        "    return result\n",
        "\n",
        "# Example usage\n",
        "async def main():\n",
        "    num = 5\n",
        "    fact = await factorial_async(num)\n",
        "    print(f\"The factorial of {num} is {fact}\")\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "id": "lISXpq42mq0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function without asynch and implement sleep I/O**\n",
        "No, adding `time.sleep()` in a synchronous function like `factorial()` will not make it non-blocking. `time.sleep()` is a blocking operation that pauses the execution of the current thread for a specified number of seconds, causing the program to wait until the sleep duration elapses before continuing.\n",
        "\n",
        "In this case, each iteration of the loop in `factorial()` will pause the execution of the current thread for 0.1 seconds, blocking the program's execution. Other tasks or operations in the program will be delayed until the sleep operation completes.\n",
        "\n",
        "Therefore, even though `time.sleep()` introduces a delay, it does not enable other tasks to run concurrently. To achieve non-blocking behavior and enable concurrency, you would need to use asynchronous programming with `asyncio` and `await` syntax, as shown in the previous example with `async def` and `await asyncio.sleep()`."
      ],
      "metadata": {
        "id": "xKA80ThgnCAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Synchronous function to calculate factorial (blocking)\n",
        "def factorial(n):\n",
        "    result = 1\n",
        "    for i in range(1, n + 1):\n",
        "        result *= i\n",
        "        # Simulate blocking I/O operation\n",
        "        # Even the function use sleep, It blocks all other functions\n",
        "        time.sleep(0.1)  # Blocking sleep\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "OkBqqPyjm6TF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resume**\n",
        "\n",
        "Functions that do not use `async` (synchronous functions) are blocking even if they perform input/output operations or use `wait` or `sleep`; they do not yield control to other processes. On the other hand, functions that use `async` yield control if they perform input/output operations, `wait`, or `sleep`."
      ],
      "metadata": {
        "id": "WnExDlGPnxXO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parallelism Example using multiprocessing:**"
      ],
      "metadata": {
        "id": "0vB-FuK-g9p-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parallel sum\n",
        "# Queue is used for processes communication\n",
        "from multiprocessing import Process, Queue\n",
        "\n",
        "# Function to perform addition on a sublist\n",
        "def sublist_add(sublist, result_queue):\n",
        "    result = sum(sublist)\n",
        "    result_queue.put(result)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Input data\n",
        "    data = [list(range(1, 101)), list(range(101, 201)), list(range(201, 301)), list(range(301, 401))]\n",
        "\n",
        "    # Create a result queue to store the results\n",
        "    result_queue = Queue()\n",
        "\n",
        "    # Create processes\n",
        "    processes = []\n",
        "    for sublist in data:\n",
        "        p = Process(target=sublist_add, args=(sublist, result_queue))\n",
        "        processes.append(p)\n",
        "        p.start()\n",
        "\n",
        "    # Wait for all processes to finish\n",
        "    for p in processes:\n",
        "        p.join()\n",
        "\n",
        "    # Retrieve results from the queue\n",
        "    results = []\n",
        "    while not result_queue.empty():\n",
        "        results.append(result_queue.get())\n",
        "\n",
        "    # Print results\n",
        "    print(\"Results:\", results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEGi2o0ni3ZU",
        "outputId": "93d50140-6c4c-481b-e6c1-757038653e82"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results: [5050, 15050, 25050, 35050]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parallel multiplication\n",
        "from multiprocessing import Process, Queue\n",
        "\n",
        "# Function to perform multiplication on a sublist\n",
        "def sublist_multiply(sublist, result_queue):\n",
        "    result = 1\n",
        "    for num in sublist:\n",
        "        result *= num\n",
        "    result_queue.put(result)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Input data\n",
        "    data = [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]]\n",
        "\n",
        "    # Create a result queue to store the results\n",
        "    result_queue = Queue()\n",
        "\n",
        "    # Create processes\n",
        "    processes = []\n",
        "    for sublist in data:\n",
        "        p = Process(target=sublist_multiply, args=(sublist, result_queue))\n",
        "        processes.append(p)\n",
        "        p.start()\n",
        "\n",
        "    # Wait for all processes to finish\n",
        "    for p in processes:\n",
        "        p.join()\n",
        "\n",
        "    # Retrieve results from the queue\n",
        "    results = []\n",
        "    while not result_queue.empty():\n",
        "        results.append(result_queue.get())\n",
        "\n",
        "    # Print results\n",
        "    print(\"Results:\", results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rimDUotkBpW",
        "outputId": "6a7eab64-f5e1-4db5-ea88-0ecd1015026d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results: [24, 1680, 11880, 43680]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Python's GIL (Global Interpreter Lock)**"
      ],
      "metadata": {
        "id": "r3lDRWmnoMVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Global Interpreter Lock (GIL) in Python is a mutex (mutual exclusion) that protects access to Python objects, preventing multiple native threads from executing Python bytecodes concurrently in the same process. This means that only one thread can execute Python bytecode at a time, regardless of the number of CPU cores available.\n",
        "\n",
        "The GIL is a design feature of the Python interpreter (CPython) and is intended to simplify memory management and provide thread safety by ensuring that only one thread executes Python bytecode at a time. However, this can lead to performance limitations, particularly in CPU-bound multithreaded applications, as it prevents true parallelism and limits the utilization of multiple CPU cores.\n",
        "\n",
        "It's important to note that the GIL only affects CPython, the reference implementation of Python. Alternative implementations such as Jython and IronPython do not have a GIL and can execute multiple threads concurrently. Additionally, asynchronous programming with `asyncio` can be used to achieve concurrency without relying on threads and bypassing the GIL."
      ],
      "metadata": {
        "id": "l6zGN8UlolHz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 1 with Threads**\n",
        "\n",
        "- We define a function `cpu_bound_calculation()` to perform a CPU-bound calculation. Each thread is assigned a unique identifier.\n",
        "- We define a function `write_to_file()` to write the result to a file. This function is protected by a lock (`file_lock`) to ensure that only one thread can write to the file at a time.\n",
        "- We define a function `calculate_and_write()` to perform the calculation and write the result to the file. This function is called by each thread.\n",
        "- In the `run_calculations()` function, we create four threads, each calling `calculate_and_write()` to perform the calculation and write the result to the file.\n",
        "- We join all the threads to wait for them to finish execution.\n",
        "\n",
        "This example demonstrates how to safely write to a file from multiple threads in Python, ensuring that only one thread writes to the file at a time using a lock."
      ],
      "metadata": {
        "id": "EaC_-Dpircm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "# Function to perform a CPU-bound calculation\n",
        "def cpu_bound_calculation(thread_id):\n",
        "    result = 0\n",
        "    for _ in range(10**7):\n",
        "        result += 1\n",
        "    return f\"Thread {thread_id}: {result}\\n\"\n",
        "\n",
        "# Function to write result to file\n",
        "def write_to_file(file, result):\n",
        "    # Lock variable access\n",
        "    with file_lock:\n",
        "        file.write(result)\n",
        "\n",
        "# Function to perform calculation and write result\n",
        "def calculate_and_write(thread_id, file):\n",
        "    result = cpu_bound_calculation(thread_id)\n",
        "    write_to_file(file, result)\n",
        "\n",
        "# Create a lock for file access\n",
        "file_lock = threading.Lock()\n",
        "\n",
        "# Function to run CPU-bound calculations and write results to file\n",
        "def run_calculations():\n",
        "    with open(\"results.txt\", \"a\") as file:\n",
        "        threads = []\n",
        "        for i in range(4):  # Create 4 threads\n",
        "            thread = threading.Thread(target=calculate_and_write, args=(i, file))\n",
        "            thread.start()\n",
        "            threads.append(thread)\n",
        "        for thread in threads:\n",
        "            thread.join()\n",
        "\n",
        "# Run CPU-bound calculations and write results to file\n",
        "run_calculations()\n"
      ],
      "metadata": {
        "id": "NNJhkx41omnq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OvW-bAsKsz-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Example 2 with Threads**\n",
        "- We have a shared variable `shared_variable` that is initially set to 0.\n",
        "- We use a lock (`lock`) to protect access to the shared variable.\n",
        "- We define three functions: `increment_shared_variable()`, `decrement_shared_variable()`, and `print_shared_variable()`, each of which accesses the shared variable within a `with lock` block.\n",
        "- The `perform_operations()` function is designed to increment and decrement the shared variable multiple times in a loop while printing its value.\n",
        "- We create four threads to call `perform_operations()` concurrently.\n",
        "- Each thread increments and decrements the shared variable within the `with lock` block to ensure thread safety.\n",
        "- After all threads finish execution, we print the final value of the shared variable.\n",
        "\n",
        "This example demonstrates how to safely manipulate a shared variable from multiple threads using a lock in Python."
      ],
      "metadata": {
        "id": "2c8k5q62s0UJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "# Shared variable\n",
        "shared_variable = 0\n",
        "\n",
        "# Lock for shared_variable access\n",
        "lock = threading.Lock()\n",
        "\n",
        "# Function to increment the shared variable\n",
        "def increment_shared_variable():\n",
        "    global shared_variable\n",
        "    with lock:\n",
        "        shared_variable += 1\n",
        "\n",
        "# Function to decrement the shared variable\n",
        "def decrement_shared_variable():\n",
        "    global shared_variable\n",
        "    with lock:\n",
        "        shared_variable -= 1\n",
        "\n",
        "# Function to print the shared variable\n",
        "def print_shared_variable():\n",
        "    with lock:\n",
        "        print(\"Shared Variable:\", shared_variable)\n",
        "\n",
        "# Function to perform operations on the shared variable\n",
        "def perform_operations():\n",
        "    for _ in range(100000):\n",
        "        increment_shared_variable()\n",
        "        decrement_shared_variable()\n",
        "        print_shared_variable()\n",
        "\n",
        "# Create threads to perform operations\n",
        "threads = []\n",
        "for _ in range(4):\n",
        "    thread = threading.Thread(target=perform_operations)\n",
        "    thread.start()\n",
        "    threads.append(thread)\n",
        "\n",
        "# Wait for all threads to finish\n",
        "for thread in threads:\n",
        "    thread.join()\n",
        "\n",
        "# Print the final value of the shared variable\n",
        "print(\"Final Shared Variable:\", shared_variable)\n"
      ],
      "metadata": {
        "id": "kghGBYyLsYRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Python, threads and processes are both mechanisms for parallel execution, but they differ in several key aspects:\n",
        "\n",
        "1. **Memory**:\n",
        "   - **Threads**: Threads within the same process share the same memory space, including global variables, heap memory, and other resources. This means that data can be easily shared between threads.\n",
        "   - **Processes**: Processes have separate memory spaces. Each process has its own address space, so data is not shared between processes by default. Inter-process communication mechanisms like pipes, queues, or shared memory need to be used to share data between processes.\n",
        "\n",
        "2. **Execution**:\n",
        "   - **Threads**: Threads are lighter-weight than processes and share the same CPU core. They are managed by the operating system's thread scheduler, which switches between threads to give the appearance of concurrent execution.\n",
        "   - **Processes**: Processes are heavier-weight than threads because they have their own memory space and resources. Each process has its own independent execution context and is managed by the operating system's process scheduler.\n",
        "\n",
        "3. **Concurrency vs. Parallelism**:\n",
        "   - **Concurrency**: Threads enable concurrent execution, allowing multiple tasks to be executed in an interleaved manner. In Python, due to the Global Interpreter Lock (GIL) in CPython, true parallelism is not achieved with threads for CPU-bound tasks (On thread is executed at a given time).\n",
        "   - **Parallelism**: Processes enable true parallel execution, where multiple tasks are executed simultaneously on multiple CPU cores. Parallelism can be achieved by using multiple processes, which can run independently of each other.\n",
        "\n",
        "4. **Communication**:\n",
        "   - **Threads**: Communication between threads is straightforward since they share memory. However, synchronization mechanisms like locks, semaphores, and condition variables are needed to ensure thread safety.\n",
        "   - **Processes**: Communication between processes is more complex because they don't share memory. Inter-process communication (IPC) mechanisms such as pipes, queues, sockets, and shared memory need to be used for communication between processes.\n",
        "\n",
        "**In summary, threads are suitable for I/O-bound tasks and situations where shared memory is required, while processes are more suitable for CPU-bound tasks and situations where isolation and true parallelism are needed.**\n",
        "\n",
        "**French: En résumé, les threads sont adaptés aux tâches liées à l'entrée/sortie et aux situations où la mémoire partagée est requise (si un thread fais un I/O, le GIL est relâché, et les autres threads peuvent s'exécuter), tandis que les processus sont plus adaptés aux tâches liées au processeur et aux situations où l'isolation et la véritable parallélisme sont nécessaires.**"
      ],
      "metadata": {
        "id": "519kKkaMt3iq"
      }
    }
  ]
}