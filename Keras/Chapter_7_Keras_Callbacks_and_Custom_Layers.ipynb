{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "IQpgkg0Jv1UX",
        "CCdyGtlqwELF",
        "HpB1qUoawVjY",
        "HePolVHCwdFz",
        "_2fUM9Wlwo9i"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Plan**\n",
        "\n",
        "**1. Introduction to callbacks**\n",
        "\n",
        "**2. Creating and using custom callback functions**\n",
        "\n",
        "**3. Implementing custom layers in Keras models**\n",
        "\n",
        "**4. Implementing custom models in Keras**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YiBklHRuTbj_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction to callbacks**"
      ],
      "metadata": {
        "id": "gT4j4edqtVxd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Callbacks in Keras are a powerful feature that allows you to intervene during the training process of your model. They provide a way to execute certain actions at various stages of training, such as before or after each epoch or batch, or when certain conditions are met. This functionality can be used to monitor performance, adjust learning rates, save models, and more.\n",
        "\n",
        "**<h2>Key Concepts</h2>**\n",
        "\n",
        "1. **Callback Functions**:\n",
        "   - Callbacks are functions or objects that are invoked during training at specific points, such as the beginning or end of an epoch, or after each batch.\n",
        "\n",
        "2. **Custom Callbacks**:\n",
        "   - Keras allows you to define custom callbacks by subclassing the `tf.keras.callbacks.Callback` class and overriding its methods.\n",
        "\n",
        "**<h2>Common Built-in Callbacks</h2>**\n",
        "\n",
        "1. **`ModelCheckpoint`**:\n",
        "   - Saves the model or weights at regular intervals, typically after each epoch.\n",
        "   - Useful for saving the best model based on validation performance.\n",
        "\n",
        "   ```python\n",
        "   from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "   checkpoint = ModelCheckpoint(\n",
        "       'best_model.h5',            # File path to save the model\n",
        "       monitor='val_loss',         # Monitor the validation loss\n",
        "       save_best_only=True,         # Save only the best model\n",
        "       mode='min',                 # Mode to determine the \"best\" model (min or max)\n",
        "       verbose=1                   # Verbosity mode\n",
        "   )\n",
        "   ```\n",
        "\n",
        "2. **`EarlyStopping`**:\n",
        "   - Stops training when a monitored metric has stopped improving.\n",
        "   - Helps prevent overfitting and unnecessary training.\n",
        "\n",
        "   ```python\n",
        "   from keras.callbacks import EarlyStopping\n",
        "\n",
        "   early_stopping = EarlyStopping(\n",
        "       monitor='val_loss',         # Monitor validation loss\n",
        "       patience=10,                # Number of epochs with no improvement to wait\n",
        "       mode='min',                 # Mode to determine the \"best\" model (min or max)\n",
        "       verbose=1                   # Verbosity mode\n",
        "   )\n",
        "   ```\n",
        "\n",
        "3. **`ReduceLROnPlateau`**:\n",
        "   - Reduces the learning rate when a metric has stopped improving.\n",
        "   - Useful for fine-tuning the learning rate.\n",
        "\n",
        "   ```python\n",
        "   from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "   reduce_lr = ReduceLROnPlateau(\n",
        "       monitor='val_loss',         # Monitor validation loss\n",
        "       factor=0.1,                 # Factor by which the learning rate will be reduced\n",
        "       patience=5,                 # Number of epochs with no improvement to wait\n",
        "       mode='min',                 # Mode to determine the \"best\" model (min or max)\n",
        "       verbose=1                   # Verbosity mode\n",
        "   )\n",
        "   ```\n",
        "\n",
        "4. **`TensorBoard`**:\n",
        "   - Provides visualization of the training process, including metrics and model graph.\n",
        "   - Integrates with TensorBoard, a tool for visualizing TensorFlow training runs.\n",
        "\n",
        "   ```python\n",
        "   from keras.callbacks import TensorBoard\n",
        "\n",
        "   tensorboard = TensorBoard(\n",
        "       log_dir='./logs',           # Directory where the logs will be saved\n",
        "       histogram_freq=1,           # Frequency (in epochs) to compute activation and weight histograms\n",
        "       write_graph=True,           # Whether to visualize the graph\n",
        "       write_images=True           # Whether to write image summaries\n",
        "   )\n",
        "   ```\n",
        "\n",
        "5. **`CSVLogger`**:\n",
        "   - Streams training and validation metrics to a CSV file.\n",
        "   - Useful for tracking and analyzing training history.\n",
        "\n",
        "   ```python\n",
        "   from keras.callbacks import CSVLogger\n",
        "\n",
        "   csv_logger = CSVLogger(\n",
        "       'training_log.csv',         # File path to save the CSV log\n",
        "       append=True,                # Append to the existing file\n",
        "       separator=',',              # Separator for the CSV file\n",
        "       verbose=1                   # Verbosity mode\n",
        "   )\n",
        "   ```\n",
        "\n",
        "**<h2>Creating Custom Callbacks</h2>**\n",
        "\n",
        "You can create your own callbacks by subclassing `tf.keras.callbacks.Callback` and implementing the methods you need. Here’s an example of a custom callback that prints the current epoch number:\n",
        "\n",
        "```python\n",
        "from keras.callbacks import Callback\n",
        "\n",
        "class PrintEpochCallback(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print(f\"Epoch {epoch+1} has ended\")\n",
        "\n",
        "# Usage\n",
        "print_epoch_callback = PrintEpochCallback()\n",
        "```\n",
        "\n",
        "**<h2>Using Callbacks During Training</h2>**\n",
        "\n",
        "To use callbacks, pass them as a list to the `callbacks` parameter of the `fit` method:\n",
        "\n",
        "```python\n",
        "model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_data=(x_test, y_test),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    callbacks=[checkpoint, early_stopping, reduce_lr, tensorboard, csv_logger, print_epoch_callback]\n",
        ")\n",
        "```\n",
        "\n",
        "**<h2>Summary</h2>**\n",
        "\n",
        "Callbacks in Keras provide a flexible way to monitor and control the training process. Common built-in callbacks include `ModelCheckpoint`, `EarlyStopping`, `ReduceLROnPlateau`, `TensorBoard`, and `CSVLogger`. You can also create custom callbacks to implement specific functionalities. By leveraging callbacks, you can make your training process more efficient, automated, and insightful."
      ],
      "metadata": {
        "id": "UaNOqtuytrYZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating and using custom callback functions**"
      ],
      "metadata": {
        "id": "hJX4k9NXuFsp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating and using custom callback functions in Keras allows you to introduce tailored behaviors during training, such as custom logging, dynamic learning rate adjustments, or any other task that needs to be executed at specific points in the training process. Below, I’ll provide a step-by-step guide to creating and using custom callbacks in Keras.\n",
        "\n",
        "**<h2>Step-by-Step Guide to Custom Callbacks</h2>**\n",
        "\n",
        "**1. Subclass the `Callback` Class**\n",
        "\n",
        "To create a custom callback, subclass `tf.keras.callbacks.Callback` and override the methods you are interested in. Common methods to override include:\n",
        "\n",
        "- `on_epoch_begin(self, epoch, logs=None)`: Called at the beginning of each epoch.\n",
        "- `on_epoch_end(self, epoch, logs=None)`: Called at the end of each epoch.\n",
        "- `on_batch_begin(self, batch, logs=None)`: Called at the beginning of each batch.\n",
        "- `on_batch_end(self, batch, logs=None)`: Called at the end of each batch.\n",
        "- `on_train_begin(self, logs=None)`: Called at the beginning of training.\n",
        "- `on_train_end(self, logs=None)`: Called at the end of training.\n",
        "\n"
      ],
      "metadata": {
        "id": "GExM4RpEu-j-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 1: Custom Callback to Print Training Time**\n",
        "\n",
        "Here’s an example of a custom callback that prints the time taken for each epoch:"
      ],
      "metadata": {
        "id": "6H8XhD_svjR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from keras.callbacks import Callback\n",
        "\n",
        "class TimeHistory(Callback):\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.epoch_start_time = time.time()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        epoch_duration = time.time() - self.epoch_start_time\n",
        "        print(f\"Epoch {epoch + 1} duration: {epoch_duration:.2f} seconds\")\n",
        "\n",
        "# Usage\n",
        "time_callback = TimeHistory()"
      ],
      "metadata": {
        "id": "UWeqqS1yveqB"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 2: Custom Callback to Save Loss Values**\n",
        "\n",
        "Here’s an example of a custom callback that saves the loss values at the end of each epoch to a list:"
      ],
      "metadata": {
        "id": "rJ7fyMe8v5gR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import Callback\n",
        "\n",
        "class LossHistory(Callback):\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.losses = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "\n",
        "    def get_losses(self):\n",
        "        return self.losses\n",
        "\n",
        "# Usage\n",
        "loss_history = LossHistory()"
      ],
      "metadata": {
        "id": "783gz3GUv9--"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 3: Custom Callback to Adjust Learning Rate**\n",
        "\n",
        "Here’s an example of a custom callback that dynamically adjusts the learning rate based on the validation loss:"
      ],
      "metadata": {
        "id": "tsvpZu50wJBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import Callback\n",
        "import numpy as np\n",
        "\n",
        "class LearningRateScheduler(Callback):\n",
        "    def __init__(self, schedule):\n",
        "        super().__init__()\n",
        "        self.schedule = schedule\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        current_lr = self.model.optimizer.learning_rate.numpy()\n",
        "        new_lr = self.schedule(epoch, logs.get('val_loss'))\n",
        "        if np.abs(new_lr - current_lr) > 1e-6:\n",
        "            self.model.optimizer.learning_rate.assign(new_lr)\n",
        "            print(f\"Learning rate adjusted to: {new_lr:.6f}\")\n",
        "\n",
        "# Define the schedule function\n",
        "def lr_schedule(epoch, val_loss):\n",
        "    if epoch < 10:\n",
        "        return 0.01\n",
        "    elif epoch < 20:\n",
        "        return 0.001\n",
        "    else:\n",
        "        return 0.0001\n",
        "\n",
        "# Usage\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)"
      ],
      "metadata": {
        "id": "JFJFXze7wM-X"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Integrate the Custom Callback into Model Training**\n",
        "\n",
        "Once you have defined your custom callback, you can integrate it into the model training process by passing it to the callbacks argument of the fit method."
      ],
      "metadata": {
        "id": "mX-hJoFKwZ7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Build a simple model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Create instances of the custom callbacks\n",
        "time_callback = TimeHistory()\n",
        "loss_history = LossHistory()\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_data=(x_test, y_test),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    callbacks=[time_callback, loss_history, lr_scheduler]\n",
        ")\n",
        "\n",
        "# Access loss values from the custom callback\n",
        "print(\"Training loss history:\", loss_history.get_losses())"
      ],
      "metadata": {
        "id": "w6un08qUwbzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementing custom layers in Keras models**"
      ],
      "metadata": {
        "id": "2zu-KMrVw2vL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing custom layers in Keras models involves subclassing the tf.keras.layers.Layer class and defining the layer's functionality, including its forward pass, initialization, and (optionally) its configuration for saving and loading.\n",
        "\n",
        "Custom layers can be useful when you need to create a new type of layer that isn't available in Keras, or when you want to experiment with novel layer designs.\n",
        "Step-by-Step Guide to Implementing Custom Layers\n",
        "\n",
        "**1. Subclass the tf.keras.layers.Layer Class**\n",
        "\n",
        "To create a custom layer, you need to subclass tf.keras.layers.Layer and override several methods:\n",
        "\n",
        "* __init__: Initialize the layer's parameters and any necessary configurations.\n",
        "* build: Create the layer’s variables. This method is called once and should be used to create any weights or state variables.\n",
        "* call: Define the computation that the layer performs. This method defines the forward pass of the layer.\n",
        "* compute_output_shape: (Optional) Specify the output shape of the layer given an input shape.\n",
        "* get_config: (Optional) Define how to serialize and deserialize the layer's configuration.\n",
        "\n"
      ],
      "metadata": {
        "id": "tCqPddJsxKJj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 1: Custom Dense Layer**\n",
        "\n",
        "Let’s create a custom dense layer that adds a bias to the output but does not use activation functions:"
      ],
      "metadata": {
        "id": "6gbqTaQgxTiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "class CustomDense(keras.layers.Layer):\n",
        "    def __init__(self, units=32, **kwargs):\n",
        "        super(CustomDense, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Create trainable weights\n",
        "        self.w = self.add_weight(\n",
        "            shape=(input_shape[-1], self.units),\n",
        "            initializer='random_normal',\n",
        "            trainable=True\n",
        "        )\n",
        "        self.b = self.add_weight(\n",
        "            shape=(self.units,),\n",
        "            initializer='zeros',\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return keras.ops.matmul(inputs, self.w) + self.b\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], self.units)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(CustomDense, self).get_config()\n",
        "        config.update({\"units\": self.units})\n",
        "        return config"
      ],
      "metadata": {
        "id": "nQqX99CDxYMN"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 2: Custom Activation Layer**\n",
        "\n",
        "Now, let’s create a custom activation layer that applies a custom function to the inputs. For example, we'll implement a layer that applies a simple piecewise function:"
      ],
      "metadata": {
        "id": "OeXdQQKMx4l5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomActivation(keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(CustomActivation, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Apply custom piecewise activation function\n",
        "        return keras.ops.where(inputs > 0, inputs, 0.1 * inputs)  # Leaky ReLU-like activation\n",
        "\n",
        "    def get_config(self):\n",
        "        return super(CustomActivation, self).get_config()\n"
      ],
      "metadata": {
        "id": "9vx5mE-jx6FN"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Use Custom Layers in a Model**\n",
        "\n",
        "Once you have defined your custom layers, you can use them in your Keras models like any other layer.\n",
        "\n",
        "**Using CustomDense Layer:**"
      ],
      "metadata": {
        "id": "ns5U3y6LyEpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Input(shape=(784,)),\n",
        "    CustomDense(128),  # Custom dense layer with 128 units\n",
        "    keras.layers.ReLU(),\n",
        "    CustomDense(10)    # Custom dense layer with 10 units\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "0gm7l9Owx2Yd",
        "outputId": "29458a07-2e24-42f6-b3a9-c8b2eb5987f0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ custom_dense (\u001b[38;5;33mCustomDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)                         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ custom_dense_1 (\u001b[38;5;33mCustomDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ custom_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomDense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ custom_dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomDense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using CustomActivation Layer:**"
      ],
      "metadata": {
        "id": "FbcG4pg4yX7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Input(shape=(784,)),\n",
        "    CustomDense(128),\n",
        "    CustomActivation(),  # Custom activation layer\n",
        "    CustomDense(10)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "Ix16aliEyZOl",
        "outputId": "d1271fc4-e020-4f34-e95d-78e25b42f396"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ custom_dense_2 (\u001b[38;5;33mCustomDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ custom_activation_1                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mCustomActivation\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ custom_dense_3 (\u001b[38;5;33mCustomDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ custom_dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomDense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ custom_activation_1                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomActivation</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ custom_dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomDense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Saving and Loading Models with Custom Layers**\n",
        "\n",
        "Custom layers need to be included in the model’s configuration to ensure they are properly saved and loaded.\n",
        "\n",
        "**Saving the Model:**"
      ],
      "metadata": {
        "id": "99S2_3ppyj4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model_with_custom_layers.keras')"
      ],
      "metadata": {
        "id": "xg9zGcDHymu8"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the Model:**\n",
        "\n",
        "To load a model with custom layers, you need to pass a custom_objects **dictionary to tf.keras.models.load_model:**"
      ],
      "metadata": {
        "id": "buH498TIy8ZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "custom_objects = {\n",
        "    'CustomDense': CustomDense,\n",
        "    'CustomActivation': CustomActivation\n",
        "}\n",
        "\n",
        "model = load_model('model_with_custom_layers.keras', custom_objects=custom_objects)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2fgwq7tzBkP",
        "outputId": "02cc87f8-5b65-499d-9190-e5374a26950a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 10 variables whereas the saved optimizer has 2 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementing custom models in Keras**"
      ],
      "metadata": {
        "id": "WuY2TWo6zYia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "class CustomSequentialModel(Model):\n",
        "    def __init__(self, units=64, **kwargs):\n",
        "        super(CustomSequentialModel, self).__init__(**kwargs)\n",
        "        # Define layers\n",
        "        self.dense1 = Dense(units, activation='relu')\n",
        "        self.dense2 = Dense(10, activation=\"softmax\")  # Output layer with 10 units\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = self.dense1(inputs)\n",
        "        x = self.dense2(x)\n",
        "        return x\n",
        "\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass\n",
        "            y_pred = self(x, training=True)\n",
        "            # Compute loss\n",
        "            loss = self.compiled_loss(y, y_pred)  # Using compiled_loss for better compatibility\n",
        "\n",
        "        # Compute gradients\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        # Apply gradients\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "\n",
        "        # Update metrics\n",
        "        for metric in self.metrics:\n",
        "            metric.update_state(y, y_pred)\n",
        "        metrics = {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "        return {**metrics, \"loss\": loss}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        x, y = data\n",
        "\n",
        "        # Forward pass\n",
        "        y_pred = self(x, training=False)\n",
        "        # Compute loss\n",
        "        loss = self.compiled_loss(y, y_pred)  # Using compiled_loss for better compatibility\n",
        "\n",
        "        # Update metrics\n",
        "        for metric in self.metrics:\n",
        "            metric.update_state(y, y_pred)\n",
        "        metrics = {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "        return {**metrics, \"loss\": loss}\n",
        "\n",
        "# Create and compile the model\n",
        "model = CustomSequentialModel(units=128)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "BKTDUJKc0I9M"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "Z4U_Y-5b0Pwl",
        "outputId": "5904af04-5149-4ece-d918-56c8517bb130"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"custom_sequential_model_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"custom_sequential_model_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "x_train = x_train.reshape(-1, 784)\n",
        "x_test = x_test.reshape(-1, 784)\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n"
      ],
      "metadata": {
        "id": "GTYEmR8A0Xpv"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fit the model\n",
        "history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNQ44MW_0Vk1",
        "outputId": "975bd6ba-81c7-493d-f8ec-f90022383ffc"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8756 - loss: 0.2582 - val_accuracy: 0.9601 - val_loss: 0.9293\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9635 - loss: 0.1161 - val_accuracy: 0.9679 - val_loss: 0.9454\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9753 - loss: 0.0794 - val_accuracy: 0.9758 - val_loss: 0.9572\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9809 - loss: 0.0606 - val_accuracy: 0.9738 - val_loss: 0.9613\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9872 - loss: 0.0462 - val_accuracy: 0.9768 - val_loss: 0.9684\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9723 - loss: 0.0784\n",
            "Test accuracy: 0.9768000245094299\n"
          ]
        }
      ]
    }
  ]
}