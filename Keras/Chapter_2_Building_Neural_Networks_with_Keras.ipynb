{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "IQpgkg0Jv1UX",
        "CCdyGtlqwELF",
        "HpB1qUoawVjY",
        "HePolVHCwdFz",
        "_2fUM9Wlwo9i"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Plan**\n",
        "\n",
        "**1. Sequential and functional model architectures**\n",
        "\n",
        "**2. Layers, activations, and loss functions**\n",
        "\n",
        "**3. Model compilation and training**\n"
      ],
      "metadata": {
        "id": "YiBklHRuTbj_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sequential and functional model architectures**"
      ],
      "metadata": {
        "id": "no5aDVp0Tmlt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keras was initially developed as an independent library but has since been integrated into TensorFlow as tf.keras. However, you can still use Keras independently without TensorFlow if you prefer. The independent version of Keras supports multiple backends, such as Theano, CNTK, or even TensorFlow. Below are the examples using Keras rather than tf.keras."
      ],
      "metadata": {
        "id": "rBt6-6ZMUUEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>Installing Standalone Keras</h2>**"
      ],
      "metadata": {
        "id": "p6PMUEugUZin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --upgrade keras-cv"
      ],
      "metadata": {
        "id": "nDN4P22TUeQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "import keras"
      ],
      "metadata": {
        "id": "LLl2Rj82UiZ3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ol0XBK9uU8fB",
        "outputId": "25e24083-4b04-4945-f8dd-13b2f6674b38"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.4.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>1. Sequential Model Architecture with Keras</h2>**\n",
        "\n",
        "The Sequential API in standalone Keras allows you to create models layer by layer.\n",
        "\n",
        "**Example: Simple Feedforward Neural Network**"
      ],
      "metadata": {
        "id": "T_gWD3tMUyf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Initialize a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add layers to the model\n",
        "model.add(Dense(32, activation='relu', input_shape=(784,)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "ReUXxPaMU4qP",
        "outputId": "27098b2f-074d-408b-8a5d-ace133ba5f0c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m25,120\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,120</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m27,882\u001b[0m (108.91 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,882</span> (108.91 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m27,882\u001b[0m (108.91 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,882</span> (108.91 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>2. . Functional Model Architecture with Keras</h2>**\n",
        "\n",
        "The Functional API in Keras is more flexible than the Sequential API and allows you to build more complex models, such as those with multiple inputs and outputs, shared layers, or non-linear topology (e.g., residual connections, multi-branch models).\n",
        "When to Use the Functional API:\n",
        "\n",
        "* When you need more flexibility than the Sequential API provides.\n",
        "* When the model has multiple inputs, multiple outputs, or non-linear layer connections.\n",
        "* When layers need to be shared across different inputs.\n",
        "\n",
        "**Example: Multi-Input and Multi-Output Model**"
      ],
      "metadata": {
        "id": "mK0_oNmJVWQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, concatenate\n",
        "\n",
        "# Define inputs\n",
        "input_1 = Input(shape=(784,))\n",
        "input_2 = Input(shape=(784,))\n",
        "\n",
        "# Define layers\n",
        "x1 = Dense(32, activation='relu')(input_1)\n",
        "x2 = Dense(32, activation='relu')(input_2)\n",
        "merged = concatenate([x1, x2])\n",
        "output = Dense(10, activation='softmax')(merged)\n",
        "\n",
        "# Create model\n",
        "model = Model(inputs=[input_1, input_2], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "_2CaT-HbVjEh",
        "outputId": "d37b1142-23a0-4ff1-bd69-811de87be8bd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m25,120\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m25,120\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                           │                        │                │ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │            \u001b[38;5;34m650\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">25,120</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">25,120</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                           │                        │                │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,890\u001b[0m (198.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,890</span> (198.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,890\u001b[0m (198.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,890</span> (198.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In this example:**\n",
        "\n",
        "* **Input layers:** Two different inputs are defined using the Input() layer.\n",
        "* **Layers:** The inputs are passed through separate Dense layers, then concatenated.\n",
        "* **Output layer:** A shared output layer is applied to the concatenated results.\n",
        "\n",
        "**Key Differences Between Sequential and Functional API**\n",
        "\n",
        "* Sequential API:\n",
        "    * Simpler and faster to set up.\n",
        "    * Ideal for models with a single input and output, where layers are arranged in a linear stack.\n",
        "    * Less flexible—cannot easily handle complex architectures with multiple branches, inputs, or outputs.\n",
        "\n",
        "* Functional API:\n",
        "    * Offers greater flexibility and control.\n",
        "    * Suitable for models with complex architectures, such as those with multiple inputs/outputs, shared layers, or non-linear connections.\n",
        "    * Requires a bit more code and understanding of Keras.\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "Both the Sequential and Functional APIs in standalone Keras provide powerful ways to build neural networks, depending on your needs. The Sequential API is perfect for straightforward tasks, while the Functional API is ideal for more complex, custom architectures."
      ],
      "metadata": {
        "id": "_yE1gAtJV0Cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Layers, activations, and loss functions**"
      ],
      "metadata": {
        "id": "ARicwORQWLr9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Keras, layers, activation functions, and loss functions are the fundamental building blocks used to construct and train neural networks. Here’s a detailed overview of each:\n",
        "\n",
        "**<h2>1. Layers in Keras</h2>**\n",
        "\n",
        "Layers are the primary building blocks of a neural network in Keras. Each layer processes input data and passes the output to the next layer.\n",
        "\n",
        "**<h2>Common Layer Types</h2>**\n",
        "\n",
        "1. **Dense (Fully Connected) Layer**:\n",
        "   - **Description**: The most common layer type in neural networks. Each neuron in a dense layer is connected to every neuron in the previous and next layers.\n",
        "   - **Usage**:\n",
        "     ```python\n",
        "     from keras.layers import Dense\n",
        "\n",
        "     model.add(Dense(units=64, activation='relu', input_shape=(784,)))\n",
        "     ```\n",
        "\n",
        "2. **Conv2D (Convolutional Layer)**:\n",
        "   - **Description**: Used primarily in computer vision tasks. This layer performs convolution operations on 2D data, such as images.\n",
        "   - **Usage**:\n",
        "     ```python\n",
        "     from keras.layers import Conv2D\n",
        "\n",
        "     model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "     ```\n",
        "\n",
        "3. **MaxPooling2D (Pooling Layer)**:\n",
        "   - **Description**: Reduces the spatial dimensions (height and width) of the input volume to decrease the computational load and prevent overfitting.\n",
        "   - **Usage**:\n",
        "     ```python\n",
        "     from keras.layers import MaxPooling2D\n",
        "\n",
        "     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "     ```\n",
        "\n",
        "4. **Flatten**:\n",
        "   - **Description**: Flattens the input data into a 1D vector, often used before feeding the data into a Dense layer.\n",
        "   - **Usage**:\n",
        "     ```python\n",
        "     from keras.layers import Flatten\n",
        "\n",
        "     model.add(Flatten())\n",
        "     ```\n",
        "\n",
        "5. **Dropout**:\n",
        "   - **Description**: A regularization technique where a fraction of input units are randomly set to 0 at each update during training to prevent overfitting.\n",
        "   - **Usage**:\n",
        "     ```python\n",
        "     from keras.layers import Dropout\n",
        "\n",
        "     model.add(Dropout(rate=0.5))\n",
        "     ```\n",
        "\n",
        "6. **LSTM (Long Short-Term Memory)**:\n",
        "   - **Description**: A type of recurrent neural network layer used for processing sequential data like time series or natural language.\n",
        "   - **Usage**:\n",
        "     ```python\n",
        "     from keras.layers import LSTM\n",
        "\n",
        "     model.add(LSTM(units=50, activation='tanh', input_shape=(timesteps, features)))\n",
        "     ```\n",
        "\n",
        "7. **Embedding**:\n",
        "   - **Description**: Converts integer indices (e.g., word indices) into dense vectors of fixed size. Commonly used in natural language processing.\n",
        "   - **Usage**:\n",
        "     ```python\n",
        "     from keras.layers import Embedding\n",
        "\n",
        "     model.add(Embedding(input_dim=10000, output_dim=64, input_length=100))\n",
        "     ```\n",
        "\n",
        "**<h2>2. Activation Functions in Keras</h2>**\n",
        "\n",
        "Activation functions introduce non-linearity into the network, allowing it to learn complex patterns. They are applied to the output of each neuron.\n",
        "\n",
        "**<h2>Common Activation Functions</h2>**\n",
        "\n",
        "1. **ReLU (Rectified Linear Unit)**:\n",
        "   - **Description**: The most widely used activation function in deep learning, which outputs the input directly if positive, otherwise outputs zero.\n",
        "   - **Usage**:\n",
        "     ```python\n",
        "     activation='relu'\n",
        "     ```\n",
        "\n",
        "2. **Sigmoid**:\n",
        "   - **Description**: Outputs a value between 0 and 1, often used in binary classification tasks.\n",
        "   - **Usage**:\n",
        "     ```python\n",
        "     activation='sigmoid'\n",
        "     ```\n",
        "\n",
        "3. **Tanh**:\n",
        "   - **Description**: Outputs values between -1 and 1, often used in hidden layers of neural networks.\n",
        "   - **Usage**:\n",
        "     ```python\n",
        "     activation='tanh'\n",
        "     ```\n",
        "\n",
        "4. **Softmax**:\n",
        "   - **Description**: Converts logits into probabilities, often used in the output layer of classification models with multiple classes.\n",
        "   - **Usage**:\n",
        "     ```python\n",
        "     activation='softmax'\n",
        "     ```\n",
        "\n",
        "5. **Leaky ReLU**:\n",
        "   - **Description**: A variant of ReLU that allows a small gradient when the unit is not active.\n",
        "   - **Usage**:\n",
        "     ```python\n",
        "     from keras.layers import LeakyReLU\n",
        "\n",
        "     model.add(Dense(64))\n",
        "     model.add(LeakyReLU(alpha=0.1))\n",
        "     ```\n",
        "\n",
        "**<h2>3. Loss Functions in Keras</h2>**\n",
        "\n",
        "Loss functions quantify the difference between the predicted output and the actual target during training. The model's goal is to minimize this loss.\n",
        "\n",
        "**<h2>Common Loss Functions</h2>**\n",
        "\n",
        "1. **Mean Squared Error (MSE)**:\n",
        "   - **Description**: Commonly used in regression tasks, it calculates the average squared difference between the predicted and actual values.\n",
        "   - **Usage**:\n",
        "     ```python\n",
        "     loss='mean_squared_error'\n",
        "     ```\n",
        "\n",
        "2. **Binary Crossentropy**:\n",
        "   - **Description**: Used for binary classification tasks, it calculates the loss for binary classification problems.\n",
        "   - **Usage**:\n",
        "     ```python\n",
        "     loss='binary_crossentropy'\n",
        "     ```\n",
        "\n",
        "3. **Categorical Crossentropy**:\n",
        "   - **Description**: Used for multi-class classification tasks, it calculates the loss when the output is one-hot encoded.\n",
        "   - **Usage**:\n",
        "     ```python\n",
        "     loss='categorical_crossentropy'\n",
        "     ```\n",
        "\n",
        "4. **Sparse Categorical Crossentropy**:\n",
        "   - **Description**: Similar to categorical crossentropy, but used when the output labels are integers instead of one-hot encoded vectors.\n",
        "   - **Usage**:\n",
        "     ```python\n",
        "     loss='sparse_categorical_crossentropy'\n",
        "     ```\n",
        "\n",
        "5. **Huber Loss**:\n",
        "   - **Description**: A combination of MSE and Mean Absolute Error, less sensitive to outliers than MSE.\n",
        "   - **Usage**:\n",
        "     ```python\n",
        "     loss='huber_loss'\n",
        "     ```\n",
        "\n",
        "**<h2>Example: Combining Layers, Activations, and Loss Functions</h2>\n",
        "\n",
        "Here’s an example of how you might combine these components in a simple Keras model:\n",
        "\n",
        "```python\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add layers\n",
        "model.add(Dense(128, input_shape=(784,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "```\n",
        "\n",
        "In this example:\n",
        "- **Layers**: A series of Dense layers, with Dropout for regularization.\n",
        "- **Activations**: ReLU for hidden layers and Softmax for the output layer.\n",
        "- **Loss Function**: Sparse categorical crossentropy is used for multi-class classification with integer labels.\n",
        "\n",
        "**<h2>Conclusion</h2>**\n",
        "\n",
        "Keras provides a rich set of tools for building and training neural networks, with a wide variety of layers, activation functions, and loss functions. Understanding how to use these components effectively is key to designing powerful models that can solve complex problems."
      ],
      "metadata": {
        "id": "WonvWd7rW2hf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model compilation and training**"
      ],
      "metadata": {
        "id": "Y3PpGWWAYbWp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you've built your model in Keras, the next steps are to compile and train it. Model compilation involves configuring the model with loss functions, optimizers, and metrics. Training the model involves fitting the model to your data. Here's a detailed guide to model compilation and training in Keras.\n",
        "\n",
        "**<h2>1. Model Compilation</h2>**\n",
        "\n",
        "Before training a model, you need to compile it. During compilation, you specify the following:\n",
        "\n",
        "- **Optimizer**: Algorithm to update the weights based on the loss function.\n",
        "- **Loss Function**: Measure of how well the model's predictions match the actual targets.\n",
        "- **Metrics**: List of metrics to evaluate the model during training and testing.\n",
        "\n",
        "**<h2>Example of Model Compilation</h2>**\n",
        "\n",
        "```python\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(784,), activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "```\n",
        "\n",
        "**<h2>2. Model Training</h2>**\n",
        "\n",
        "Training the model involves using the `fit` method, which performs the following steps:\n",
        "\n",
        "- **Feed**: Pass the training data through the model.\n",
        "- **Compute**: Calculate the loss using the loss function.\n",
        "- **Update**: Adjust the weights using the optimizer.\n",
        "- **Repeat**: Iterate over the data for a specified number of epochs.\n",
        "\n",
        "**<h2>Key Parameters for `fit`</h2>**\n",
        "\n",
        "- **x**: Input data (features).\n",
        "- **y**: Target data (labels).\n",
        "- **batch_size**: Number of samples per gradient update.\n",
        "- **epochs**: Number of complete passes through the training data.\n",
        "- **validation_data**: Data on which to evaluate the loss and metrics at the end of each epoch.\n",
        "\n",
        "**<h2>Example of Model Training</h2>\n",
        "\n",
        "```python\n",
        "# Assuming `x_train`, `y_train`, `x_val`, and `y_val` are your datasets\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=32,\n",
        "                    epochs=10,\n",
        "                    validation_data=(x_val, y_val))\n",
        "\n",
        "# Print training history keys\n",
        "print(history.history.keys())\n",
        "```\n",
        "\n",
        "**<h2>3. Monitoring Training with Callbacks</h2>**\n",
        "\n",
        "Keras provides callbacks that can be used to monitor the training process. Common callbacks include:\n",
        "\n",
        "- **EarlyStopping**: Stop training when a monitored metric has stopped improving.\n",
        "- **ModelCheckpoint**: Save the model after every epoch.\n",
        "- **TensorBoard**: Log training metrics for visualization in TensorBoard.\n",
        "\n",
        "**<h2>Example of Using Callbacks</h2>**\n",
        "\n",
        "```python\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "# Model checkpoint callback\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss')\n",
        "\n",
        "# Fit the model with callbacks\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=32,\n",
        "                    epochs=50,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    callbacks=[early_stopping, model_checkpoint])\n",
        "```\n",
        "\n",
        "**<h2>4. Evaluating the Model</h2>**\n",
        "\n",
        "After training, you should evaluate the model's performance on test data to check its generalization ability.\n",
        "\n",
        "**<h2>Example of Model Evaluation</h2>**\n",
        "\n",
        "```python\n",
        "# Assuming `x_test` and `y_test` are your test datasets\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test loss: {test_loss}')\n",
        "print(f'Test accuracy: {test_accuracy}')\n",
        "```\n",
        "\n",
        "**<h2>5. Making Predictions</h2>**\n",
        "\n",
        "Once the model is trained and evaluated, you can use it to make predictions on new data.\n",
        "\n",
        "**<h2>Example of Making Predictions</h2>**\n",
        "\n",
        "```python\n",
        "# Assuming `x_new` is your new dataset\n",
        "\n",
        "predictions = model.predict(x_new)\n",
        "print(predictions)\n",
        "```\n",
        "\n",
        "**<h2>Putting It All Together</h2>**\n",
        "\n",
        "Here’s a full example that combines model building, compilation, training with validation, and evaluation:\n",
        "\n",
        "```python\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load and preprocess data\n",
        "digits = load_digits()\n",
        "x = digits.data\n",
        "y = digits.target\n",
        "\n",
        "x = StandardScaler().fit_transform(x)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(64,), activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=32,\n",
        "                    epochs=50,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks=[early_stopping, model_checkpoint])\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test loss: {test_loss}')\n",
        "print(f'Test accuracy: {test_accuracy}')\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(x_test[:5])\n",
        "print(predictions)\n",
        "```\n",
        "\n",
        "**<h2>Conclusion</h2>**\n",
        "\n",
        "Model compilation and training are crucial steps in the machine learning workflow. Keras provides a straightforward and powerful interface for these tasks, allowing you to configure and monitor your models effectively. By understanding how to compile, train, evaluate, and make predictions with your models, you can harness the full power of neural networks for your tasks."
      ],
      "metadata": {
        "id": "kgCv3-kJY2xS"
      }
    }
  ]
}